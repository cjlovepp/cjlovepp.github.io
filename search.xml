<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[redis-jedis使用管道(pipeline)]]></title>
    <url>%2F2018%2F08%2F22%2Fredis-jedis%E4%BD%BF%E7%94%A8%E7%AE%A1%E9%81%93-pipeline%2F</url>
    <content type="text"><![CDATA[前言Redis的pipeline(管道)功能在命令行中没有，但redis是支持pipeline的，而且在各个语言版的client中都有相应的实现。 由于网络开销延迟，就算redis server端有很强的处理能力，也会由于收到的client消息少，而造成吞吐量小。当client 使用pipelining 发送命令时，redis server必须将部分请求放到队列中（使用内存），执行完毕后一次性发送结果；如果发送的命令很多的话，建议对返回的结果加标签，当然这也会增加使用的内存； Pipeline在某些场景下非常有用，比如有多个command需要被“及时的”提交，而且他们对相应结果没有互相依赖，对结果响应也无需立即获得，那么pipeline就可以充当这种“批处理”的工具；而且在一定程度上，可以较大的提升性能，性能提升的原因主要是TCP连接中减少了“交互往返”的时间。 不过在编码时请注意，pipeline期间将“独占”链接，此期间将不能进行非“管道”类型的其他操作，直到pipeline关闭；如果你的pipeline的指令集很庞大，为了不干扰链接中的其他操作，你可以为pipeline操作新建Client链接，让pipeline和其他正常操作分离在2个client中。不过pipeline事实上所能容忍的操作个数，和socket-output缓冲区大小/返回结果的数据尺寸都有很大的关系；同时也意味着每个redis-server同时所能支撑的pipeline链接的个数，也是有限的，这将受限于server的物理内存或网络接口的缓冲能力。 原理说明Redis使用的是客户端-服务器（CS）模型和请求/响应协议的TCP服务器。这意味着通常情况下一个请求会遵循以下步骤： 客户端向服务端发送一个查询请求，并监听Socket返回，通常是以阻塞模式，等待服务端响应。 服务端处理命令，并将结果返回给客户端。 Redis客户端与Redis服务器之间使用TCP协议进行连接，一个客户端可以通过一个socket连接发起多个请求命令。每个请求命令发出后client通常会阻塞并等待redis服务器处理，redis处理完请求命令后会将结果通过响应报文返回给client，因此当执行多条命令的时候都需要等待上一条命令执行完毕才能执行。其执行过程如下图： 由于通信会有网络延迟，假如client和server之间的包传输时间需要0.125秒。那么上面的三个命令6个报文至少需要0.75秒才能完成。这样即使redis每秒能处理100个命令，而我们的client也只能一秒钟发出四个命令。这显然没有充分利用 redis的处理能力。 而管道（pipeline）可以一次性发送多条命令并在执行完后一次性将结果返回，pipeline通过减少客户端与redis的通信次数来实现降低往返延时时间，而且Pipeline 实现的原理是队列，而队列的原理是时先进先出，这样就保证数据的顺序性。 Pipeline 的默认的同步的个数为53个，也就是说arges中累加到53条数据时会把数据提交。其过程如下图所示：client可以将三个命令放到一个tcp报文一起发送，server则可以将三条命令的处理结果放到一个tcp报文返回。需要注意到是用 pipeline方式打包命令发送，redis必须在处理完所有命令前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并不是打包的命令越多越好。具体多少合适需要根据具体情况测试。 Jedis演示使用Pipeline在对Redis批量读写的时候，性能上有非常大的提升。使用Java测试了一下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import java.util.HashMap;import java.util.Map;import java.util.Set;import redis.clients.jedis.Jedis;import redis.clients.jedis.Pipeline;import redis.clients.jedis.Response;public class Test &#123; public static void main(String[] args) throws Exception &#123; Jedis redis = new Jedis("127.0.0.1", 6379, 400000); Map&lt;String, String&gt; data = new HashMap&lt;String, String&gt;(); redis.select(8); redis.flushDB(); // hmset long start = System.currentTimeMillis(); // 直接hmset for (int i = 0; i &lt; 10000; i++) &#123; data.clear(); data.put("k_" + i, "v_" + i); redis.hmset("key_" + i, data); &#125; long end = System.currentTimeMillis(); System.out.println("dbsize:[" + redis.dbSize() + "] .. "); System.out.println("hmset without pipeline used [" + (end-start)/1000 + "] seconds .."); redis.select(8); redis.flushDB(); // 使用pipeline hmset Pipeline p = redis.pipelined(); start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000; i++) &#123; data.clear(); data.put("k_" + i, "v_" + i); p.hmset("key_" + i, data);//将命令缓存起来 &#125; p.sync();//一次性提交所有命令 end = System.currentTimeMillis(); System.out.println("dbsize:[" + redis.dbSize() + "] .. "); System.out.println("hmset with pipeline used [" + (end-start)/1000 + "] seconds .."); // hmget Set keys = redis.keys("*"); // 直接使用Jedis hgetall start = System.currentTimeMillis(); Map&lt;String, Map&lt;String, String&gt;&gt; result = new HashMap&lt;String, Map&lt;String, String&gt;&gt;(); for (String key : keys) &#123; result.put(key, redis.hgetAll(key)); &#125; end = System.currentTimeMillis(); System.out.println("result size:[" + result.size() + "] .."); System.out.println("hgetAll without pipeline used [" + (end-start)/1000 + "] seconds .."); // 使用pipeline hgetall Map&lt;String, Response&lt;Map&lt;String, String&gt;&gt;&gt; responses = new HashMap&lt;String, Response&lt;Map&lt;String, String&gt;&gt;&gt;(keys.size()); result.clear(); start = System.currentTimeMillis(); for (String key : keys) &#123; responses.put(key, p.hgetAll(key));//缓存命令，并将结果集放入到responses中，注意，这里并没有正在返回结果 &#125; p.sync();//提交所有指令 for (String k : responses.keySet()) &#123;//一次性获取结果，因为pipeline是基于队列的所以顺序也能得到保障 result.put(k, responses.get(k).get()); &#125; end = System.currentTimeMillis(); System.out.println("result size:[" + result.size() + "] .."); System.out.println("hgetAll with pipeline used [" + (end-start)/1000 + "] seconds .."); redis.disconnect(); &#125;&#125; 测试结果：123456789//使用pipeline来批量读写10000条记录，就是小菜一碟，秒完。dbsize:[10000] ..hmset without pipeline used [243] seconds ..dbsize:[10000] ..hmset with pipeline used [0] seconds ..result size:[10000] ..hgetAll without pipeline used [243] seconds ..result size:[10000] ..hgetAll with pipeline used [0] seconds .. pipeline源码解读Pipeline类的结构 Jedis的Pipeline的实现看下上面的使用例子123456Pipeline p = redis.pipelined();....for()&#123; p.hmset("key_" + i, data);//将命令缓存起来&#125;p.sync(); 获取Pipeline对象BinaryJedis有一个成员变量pipeline，通过其pipeline()方法可以获取Pipeline对象 对的，就是它 pipeline()方法就干了一件事情，new了一个Pipeline对象，并设置了该对象的client属性！ Pipeline对象set方法干了啥pipeline的set方法实际调用的是Pipelinebase类（Pipeline父类的父类）的set方法：而getClient调用子类的实现： 调用client的set操作调用client的set操作跟踪源码发现实际是调用了sendCommand(Command.SET,key,value)方法。注意了，所有的cmd与参数都写入了outputstream Jedis定义了自己的输入流与输出流，现在所有的commands都在outputstream里面了，但是还没有传到redis客户端 Pipeline对象sync方法干了啥在上面Pipelinebase的set方法的最后了，调了一个getResponse()方法。该方法相当于把每一次的请求操作加入到一个Queue里面，这个队列有啥用？先放在这里！来看一下万恶的sync（）方法，注意红色的部分： 这个getPipelinedResponseLength()就是获取刚才的那个Queue的长度； 看看getMany()方法，一上来就fush(),这下前面代码循环写入的那么多set命名全部传到redis server了！ ps:flush刷新此输出流并强制写出所有缓冲的输出字节。flush 的常规协定是：如果此输出流的实现已经缓冲了以前写入的任何字节，则调用此方法指示应将这些字节立即写入它们预期的目标。 generateResponse(o)就是拿到返回值了，sync是没有返回值的，syncAndReturnAll有返回值 适用场景有些系统可能对可靠性要求很高，每次操作都需要立马知道这次操作是否成功，是否数据已经写进redis了，那这种场景就不适合。 还有的系统，可能是批量的将数据写入redis，允许一定比例的写入失败，那么这种场景就可以使用了，比如10000条一下进入redis，可能失败了2条无所谓，后期有补偿机制就行了，比如短信群发这种场景，如果一下群发10000条，按照第一种模式去实现，那这个请求过来，要很久才能给客户端响应，这个延迟就太长了，如果客户端请求设置了超时时间5秒，那肯定就抛出异常了，而且本身群发短信要求实时性也没那么高，这时候用pipeline最好了。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境安装Postgresql]]></title>
    <url>%2F2018%2F08%2F16%2FLinux%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85Postgresql%2F</url>
    <content type="text"><![CDATA[前言 Linux版本：CentOS PostgresSQL版本：9.5.6 安装下载安装软件包可直接去官网下载，下载后直接找个目录放进去就行，我这边的目录为’/usr/lib/pg/‘ 注意：该目录不是安装目录，所以安装完成后即可删除 解压1tar -zxvf postgresql-9.5.6.tar.gz 编译安装12345./configuremakemake install ./configure是检查当前环境能否安装PG，同时也可以使用 ./configure --help查看参数命令 这里注意下--prefix=PREFIX该参数用于指定pg的安装目录，默认是/usr/local/pgsql这里我直接使用默认值。 ./configure检测可能会提示系统未安装gcc等lib库，根据提示安装即可 创建postgres用户posgresql默认使用postgres用户12345adduser postgresmkdir /usr/local/pgsql/datachown postgres /usr/local/pgsql/data 配置数据库配置远程访问需要修改两个配置文件postgresql.conf和pg_hba.conf 修改监听地址123#listen_addresses=’localhost’#将上面这行改成如下listen_addresses=’*’ 添加IP授权123# 这是在/pgsql/data/pg_hba.conf文件里加# IPv4 myhost connections:host all all 0.0.0.0/0 trust 这里设置了对所有IP开发，可修改trust为password为远程登录设置密码，重启后生效 启动/重启1bin/pg_ctl start -D /mount/pgsql_data/ -l /mount/pgsql_log //重启restart 设置远程登陆账户和密码服务器本地登陆postgresql数据库（默认是不需要密码的）1234567[postgres@localhost pgsql]$ pwd/usr/local/pgsql[postgres@localhost pgsql]$ bin/psqlpsql.bin (9.5.9)Type "help" for help. 创建角色，并且给角色设置密码: 123postgres=# create user testwjw with password 'Zykj@5&amp;^%996';CREATE ROLE 修改数据库用户和密码： 123postgres=# alter user testwjw with password '558996';ALTER ROLE 指定字符集创建数据库testdb1，并且授权给testwjw 123postgres=# create database testdb1 with encoding='utf8' owner=testwjw;CREATE DATABASE 授权： 123postgres=# grant all privileges on database testdb1 to testwjw; GRANT 修改postgresql.conf文件中的端口和监听主机:postsql默认安装后是监听本机127.0.0.1 默认端口是5432,是不能够远程登陆的，所以要修改监听主机地址postgresql数据库的配置文件是:postgresql.conf,所在位置是：postgresql初始化时所指定的data数据目录下：具体可参照上文的配置 重启postgresql服务生效：命令行下基础命令基础查看指令 连接数据库，默认的用户和数据库postgres: psql -U user -d dbname 切换数据库，相当于mysql的use dbname : \c dbname 列举数据库，相当于mysql的show databases： \l 列举表，相当于mysql的show tables ： \dt 查看表结构，相当于desc tblname,show columns from tbname ：\d tblname 查看索引 : \di 退出 psql: \q 数据库操作相关指令 创建数据库： create database [数据库名]; 删除数据库： drop database [数据库名]; *重命名一个表： alter table [表名A] rename to [表名B]; *删除一个表： drop table [表名]; *在已有的表里添加字段： alter table [表名] add column [字段名] [类型]; *删除表中的字段： alter table [表名] drop column [字段名]; *重命名一个字段：alter table [表名] rename column [字段名A] to [字段名B]; *给一个字段设置缺省值： alter table [表名] alter column [字段名] set default [新的默认值]; *去除缺省值：alter table [表名] alter column [字段名] drop default; 在表中插入数据： insert into 表名 ([字段名m],[字段名n],......) values ([列m的值],[列n的值],......); 修改表中的某行某列的数据： update [表名] set [目标字段名]=[目标值] where [该行特征]; 删除表中某行数据： delete from [表名] where [该行特征]; 删空整个表 : delete from [表名]; 创建表： create table ([字段名1] [类型1] ;,[字段名2] [类型2],......&lt;,primary key (字段名m,字段名n,...)&gt;;); 显示 PostgreSQL 的使用和发行条款 \copyright 显示或设定用户端字元编码: \encoding [字元编码名称] SQL 命令语法上的说明，用 * 显示全部命令 : \h [名称] 备份还原相关指令可以使用pg_dump和pg_dumpall来完成。比如备份sales数据库：pg_dump drupal&gt;/opt/Postgresql/backup/1.bak 删除库的时候报错12ERROR: database "temp_test_yang" is being accessed by other usersDETAIL: There are 4 other sessions using the database. 说明该temp_test_yang库正在被人连接。解决方法是：查询出连接该数据库的进程，并将其杀死(比较暴力)select pg_terminate_backend(pid) from pg_stat_activity where DATNAME = ‘temp_test_yang’;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java任务调度框架]]></title>
    <url>%2F2018%2F08%2F09%2FJava%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[前言在进行Web开发时，我们经常会遇到任务调度的需求，要求你在某个特定的时间段执行某个任务。这里对JAVA的几种任务调度的实现做下学习记录：Timer、ScheduleExecutor、Quartz、JCronTab。 Timerjava.util.Timer提供了一种简单的任务调度实现方法：123456789101112131415161718192021222324252627282930package com.ibm.scheduler; import java.util.Timer; import java.util.TimerTask; public class TimerTest extends TimerTask &#123; private String jobName = ""; public TimerTest(String jobName) &#123; super(); this.jobName = jobName; &#125; @Override public void run() &#123; System.out.println("execute " + jobName); &#125; public static void main(String[] args) &#123; Timer timer = new Timer(); long delay1 = 1 * 1000; long period1 = 1000; // 从现在开始 1 秒钟之后，每隔 1 秒钟执行一次 job1 timer.schedule(new TimerTest("job1"), delay1, period1); long delay2 = 2 * 1000; long period2 = 2000; // 从现在开始 2 秒钟之后，每隔 2 秒钟执行一次 job2 timer.schedule(new TimerTest("job2"), delay2, period2); &#125;&#125; 输出结果：123456execute job1 execute job1 execute job2 execute job1 execute job1 execute job2 使用 Timer 实现任务调度的核心类是 Timer 和 TimerTask。其中Timer负责设定TimerTask的起始与间隔执行时间。使用者只需要创建一个 TimerTask 的继承类，实现自己的 run 方法，然后将其丢给 Timer 去执行即可。 Timer 的设计核心是一个 TaskList 和一个 TaskThread。Timer 将接收到的任务丢到自己的 TaskList 中，TaskList 按照 Task 的最初执行时间进行排序。TimerThread 在创建 Timer 时会启动成为一个守护线程。这个线程会轮询所有任务，找到一个最近要执行的任务，然后休眠，当到达最近要执行任务的开始时间点，TimerThread 被唤醒并执行该任务。之后 TimerThread 更新最近一个要执行的任务，继续休眠。 Timer 的优点在于简单易用，但由于 所有任务都是由同一个线程来调度,因此所有任务都是串行执行的，同一时间只能有一个任务在执行，前一个任务的延迟或异常都将会影响到之后的任务。 ScheduledExecutor鉴于 Timer 的上述缺陷，Java 5 推出了基于线程池设计的ScheduledExecutor。其设计思想是，每一个被调度的任务都会由线程池中一个线程去执行，因此任务是并发执行的，相互之间不会受到干扰。需要注意的是，只有当任务的执行时间到来时，ScheduedExecutor才会真正启动一个线程，其余时间 ScheduledExecutor 都是在轮询任务的状态。123456789101112131415161718192021222324252627282930313233343536package com.ibm.scheduler;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;public class ScheduledExecutorTest implements Runnable &#123; private String jobName = ""; public ScheduledExecutorTest(String jobName) &#123; super(); this.jobName = jobName; &#125; @Override public void run() &#123; System.out.println("execute " + jobName); &#125; public static void main(String[] args) &#123; ScheduledExecutorService service = Executors.newScheduledThreadPool(10); long initialDelay1 = 1; long period1 = 1; // 从现在开始1秒钟之后，每隔1秒钟执行一次job1 service.scheduleAtFixedRate( new ScheduledExecutorTest("job1"), initialDelay1, period1, TimeUnit.SECONDS); long initialDelay2 = 1; long delay2 = 1; // 从现在开始2秒钟之后，每隔2秒钟执行一次job2 service.scheduleWithFixedDelay( new ScheduledExecutorTest("job2"), initialDelay2, delay2, TimeUnit.SECONDS); &#125;&#125; 输出：123456execute job1execute job1execute job2execute job1execute job1execute job2 ScheduledExecutorService的两种常用方法： scheduleAtFixedRate:每次执行时间为上一次任务开始起向后推一个时间间隔，即每次执行时间为 :initialDelay, initialDelay+period, initialDelay+2*period, ...； scheduleWithFixedDelay:每次执行时间为上一次任务结束起向后推一个时间间隔，即每次执行时间为：initialDelay, initialDelay+executeTime+delay, initialDelay+2*executeTime+2*delay。 由此可见，ScheduleAtFixedRate是基于固定时间间隔进行任务调度，ScheduleWithFixedDelay取决于每次任务执行的时间长短，是基于不固定时间间隔进行任务调度。 QuartzQuartz可以说是使用相当广泛的任务调度框架了，它够支持更多更负责的调度需求，同时Quartz在设计上将Job和Trigger分离实现了松耦合，这大大增强了任务配置的灵活性 简单的例子用 Quartz 实现每星期二 16:38 的调度安排：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.ibm.scheduler;import java.util.Date;import org.quartz.Job;import org.quartz.JobDetail;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.quartz.Scheduler;import org.quartz.SchedulerFactory;import org.quartz.Trigger;import org.quartz.helpers.TriggerUtils;public class QuartzTest implements Job &#123; @Override //该方法实现需要执行的任务 public void execute(JobExecutionContext arg0) throws JobExecutionException &#123; System.out.println("Generating report - " + arg0.getJobDetail().getFullName() + ", type =" + arg0.getJobDetail().getJobDataMap().get("type")); System.out.println(new Date().toString()); &#125; public static void main(String[] args) &#123; try &#123; // 创建一个Scheduler SchedulerFactory schedFact = new org.quartz.impl.StdSchedulerFactory(); Scheduler sched = schedFact.getScheduler(); sched.start(); // 创建一个JobDetail，指明name，groupname，以及具体的Job类名， //该Job负责定义需要执行任务 JobDetail jobDetail = new JobDetail("myJob", "myJobGroup", QuartzTest.class); jobDetail.getJobDataMap().put("type", "FULL"); // 创建一个每周触发的Trigger，指明星期几几点几分执行 Trigger trigger = TriggerUtils.makeWeeklyTrigger(3, 16, 38); trigger.setGroup("myTriggerGroup"); // 从当前时间的下一秒开始执行 trigger.setStartTime(TriggerUtils.getEvenSecondDate(new Date())); // 指明trigger的name trigger.setName("myTrigger"); // 用scheduler将JobDetail与Trigger关联在一起，开始调度任务 sched.scheduleJob(jobDetail, trigger); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 结果：1234Generating report - myJobGroup.myJob, type =FULLTue Feb 8 16:38:00 CST 2011Generating report - myJobGroup.myJob, type =FULTue Feb 15 16:38:00 CST 2011 非常简洁地实现了一个复杂的任务调度。Quartz 设计的核心类包括 Scheduler, Job 以及Trigger。其中，Job负责定义需要执行的任务，Trigger 负责设置调度策略，Scheduler 将二者组装在一起，并触发任务开始执行。 Job只需要创建一个 Job 的继承类，实现 execute 方法。JobDetail 负责封装 Job 以及 Job 的属性，并将其提供给 Scheduler 作为参数。每次 Scheduler 执行任务时，首先会创建一个 Job 的实例，然后再调用 execute 方法执行。Quartz 没有为 Job 设计带参数的构造函数，因此需要通过额外的 JobDataMap 来存储 Job 的属性。JobDataMap 可以存储任意数量的 Key，Value 对，例如：12345jobDetail.getJobDataMap().put("myDescription", "my job description"); jobDetail.getJobDataMap().put("myValue", 1998); ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add("item1"); jobDetail.getJobDataMap().put("myArray", list); JobDataMap 中的数据可以通过下面的方式获取：12345678910111213141516171819public class JobDataMapTest implements Job &#123; @Override public void execute(JobExecutionContext context) throws JobExecutionException &#123; //从context中获取instName，groupName以及dataMap String instName = context.getJobDetail().getName(); String groupName = context.getJobDetail().getGroup(); JobDataMap dataMap = context.getJobDetail().getJobDataMap(); //从dataMap中获取myDescription，myValue以及myArray String myDescription = dataMap.getString("myDescription"); int myValue = dataMap.getInt("myValue"); ArrayList&lt;String&gt; myArray = (ArrayListlt;Strin&gt;) dataMap.get("myArray"); System.out.println(" Instance =" + instName + ", group = " + groupName + ", description = " + myDescription + ", value =" + myValue + ", array item0 = " + myArray.get(0)); &#125;&#125; TriggerTrigger 的作用是设置调度策略。Quartz 设计了多种类型的 Trigger，其中最常用的是 SimpleTrigger 和 CronTrigger。 SimpleTriggerSimpleTrigger 适用于在某一特定的时间执行一次，或者在某一特定的时间以某一特定时间间隔执行多次。上述功能决定了 SimpleTrigger 的参数包括 start-time, end-time, repeat count, 以及 repeat interval。 Repeat count: 重复次数取值为大于或等于零的整数，或者常量 SimpleTrigger.REPEAT_INDEFINITELY。 Repeat interval: 执行间隔取值为大于或等于零的长整型。当 Repeat interval 取值为0并且 Repeat count取值大于零时，将会触发任务的并发执行。 Start-time 与 end-time 取值为 java.util.Date。当同时指定 end-time 与 repeat count 时，优先考虑 end-time。一般地，可以指定 end-time，并设定 repeat count 为 REPEAT_INDEFINITELY。 以下是 SimpleTrigger 的构造方法：123456public SimpleTrigger(String name, String group, Date startTime, Date endTime, int repeatCount, long repeatInterval) CronTriggerCronTrigger 的用途更广，相比基于特定时间间隔进行调度安排的 SimpleTrigger，CronTrigger 主要适用于基于日历的调度安排。例如：每星期二的 16:38:10 执行，每月一号执行，以及更复杂的调度安排等。CronTrigger 同样需要指定 start-time 和 end-time，其核心在于 Cron 表达式,由七个字段组成（补充中有关于Cron表达式的说明）1234567Seconds Minutes Hours Day-of-Month Month Day-of-Week Year (Optional field) Job 与 Trigger 的松耦合设计是 Quartz 的一大特点，其优点在于同一个 Job 可以绑定多个不同的 Trigger，同一个 Trigger 也可以调度多个 Job，灵活性很强。 Listener除了上述基本的调度功能，Quartz 还提供了 listener 的功能。主要包含三种 listener：JobListener，TriggerListener 以及 SchedulerListener。当系统发生故障，相关人员需要被通知时，Listener 便能发挥它的作用。最常见的情况是，当任务被执行时，系统发生故障，Listener 监听到错误，立即发送邮件给管理员。下面给出 JobListener 的实例：123456789101112131415161718192021222324252627import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.quartz.JobListener;import org.quartz.SchedulerException;public class MyListener implements JobListener&#123; @Override public String getName() &#123; return "My Listener"; &#125; @Override public void jobWasExecuted(JobExecutionContext context, JobExecutionException jobException) &#123; if(jobException != null)&#123; try &#123; //停止Scheduler context.getScheduler().shutdown(); System.out.println("Error occurs when executing jobs, shut down the scheduler "); // 给管理员发送邮件… &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 使用者只需要创建一个 JobListener 的继承类，重载需要触发的方法即可。当然，需要将 listener 的实现类注册到 Scheduler 和 JobDetail 中：12sched.addJobListener(new MyListener()); jobDetail.addJobListener("My Listener"); // listener 的名字 也可以将 listener 注册为全局 listener，这样便可以监听 scheduler 中注册的所有任务 :1sched.addGlobalJobListener(new MyListener()); JobStoresQuartz的另一显著优点在于持久化，即将任务调度的相关数据保存下来。这样，当系统重启后，任务被调度的状态依然存在于系统中，不会丢失。默认情况 下，Quartz采用的是org.quartz.simpl.RAMJobStore，在这种情况下，数据仅能保存在内存中，系统重启后会全部丢失。若想持久化数据，需要采用 org.quartz.simpl.JDBCJobStoreTX。实现持久化的第一步，是要创建 Quartz 持久化所需要的表格。在 Quartz 的发布包 docs/dbTables 中可以找到相应的表格创建脚本。Quartz 支持目前大部分流行的数据库。本文以 DB2 为例，所需要的脚本为 tables_db2.sql。首先需要对脚本做一点小的修改，即在开头指明 Schema：1SET CURRENT SCHEMA quartz; 然后创建数据库 sched，执行 tables_db2.sql 创建持久化所需要的表格。 第二步，配置数据源。数据源与其它所有配置，例如 ThreadPool，均放在 quartz.properties 里：12345678910111213141516# Configure ThreadPool org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool org.quartz.threadPool.threadCount = 5 org.quartz.threadPool.threadPriority = 4 # Configure Datasources org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate org.quartz.jobStore.dataSource = db2DS org.quartz.jobStore.tablePrefix = QRTZ_ org.quartz.dataSource.db2DS.driver = com.ibm.db2.jcc.DB2Driver org.quartz.dataSource.db2DS.URL = jdbc:db2://localhost:50001/sched org.quartz.dataSource.db2DS.user = quartz org.quartz.dataSource.db2DS.password = passw0rd org.quartz.dataSource.db2DS.maxConnections = 5 使用时只需要将 quatz.properties 放在 classpath 下面，再次运行之前的任务调度实例，trigger、job 等信息便会被记录在数据库中。重启服务后将数据库中记录的任务调度数据重新导入程序运行：12345678910111213141516171819202122package com.ibm.scheduler;import org.quartz.Scheduler;import org.quartz.SchedulerException;import org.quartz.SchedulerFactory;import org.quartz.Trigger;import org.quartz.impl.StdSchedulerFactory; public class QuartzReschedulerTest&#123; public static void main(String[]args) throws SchedulerException&#123; //初始化一个 Schedule Factory SchedulerFactory schedulerFactory = new StdSchedulerFactory(); //从 schedule factory 中获取 scheduler Scheduler scheduler = schedulerFactory.getScheduler(); // 从 schedule factory 中获取 trigger Trigger trigger = scheduler.getTrigger("myTrigger","myTriggerGroup"); // 重新开启调度任务 scheduler.rescheduleJob("myTrigger", "myTriggerGroup", trigger); scheduler.start(); &#125;&#125; 上面代码中，schedulerFactory.getScheduler() 将 quartz.properties 的内容加载到内存，然后根据数据源的属性初始化数据库的链接，并将数据库中存储的数据加载到内存。之后，便可以在内存中查询某一具体的 trigger，并将其重新启动。这时候重新查询 qrtz_simple_triggers 中的数据，发现 times_triggered 值比原来增长了。 JCronTabCrontab 是一个非常方便的用于 unix/linux 系统的任务调度命令。JCronTab 则是一款完全按照 crontab 语法编写的 java 任务调度工具。 总结对于简单的基于起始时间点与时间间隔的任务调度，使用 Timer 就足够了；如果需要同时调度多个任务，基于线程池的 ScheduledTimer 是更为合适的选择；当任务调度的策略复杂到难以凭借起始时间点与时间间隔来描述时，Quartz 与 JCronTab 则体现出它们的优势。熟悉 Unix/Linux 的开发人员更倾向于 JCronTab，且 JCronTab 更适合与 Web 应用服务器相结合。Quartz 的 Trigger 与 Job 松耦合设计使其更适用于 Job 与 Trigger 的多对多应用场景。 补充Spring Boot集成QuartzcronExpression表达式介绍 字段 允许值 允许的特殊字符 秒 0-59 , - * / 分 0-59 , - * / 小时 0-23 , - * / 日期 1-31 , - * / L W C 月份 1-12 或者 JAN-DEC , - * / 星期 1-7 或者 SUN-SAT , - * / L C # 年（可选） 留空, 1970-2099 , - * / 如上面的表达式所示: “*”字符被用来指定所有的值。如：”*“在分钟的字段域里表示“每分钟”。 “-”字符被用来指定一个范围。如：“10-12”在小时域意味着“10点、11点、12点”。 “,”字符被用来指定另外的值。如：“MON,WED,FRI”在星期域里表示”星期一、星期三、星期五”. “?”字符只在日期域和星期域中使用。它被用来指定“非明确的值”。当你需要通过在这两个域中的一个来指定一些东西的时候，它是有用的。看下面的例子你就会明白。 “L”字符指定在月或者星期中的某天（最后一天）。即“Last ”的缩写。但是在星期和月中“Ｌ”表示不同的意思，如：在月子段中“L”指月份的最后一天-1月31日，2月28日，如果在星期字段中则简单的表示为“7”或者“SAT”。如果在星期字段中在某个value值得后面，则表示“某月的最后一个星期value”,如“6L”表示某月的最后一个星期五。 “W”字符只能用在月份字段中，该字段指定了离指定日期最近的那个星期日。 “#”字符只能用在星期字段，该字段指定了第几个星期value在某月中 每一个元素都可以显式地规定一个值（如6），一个区间（如9-12），一个列表（如9，11，13）或一个通配符（如*）。“月份中的日期”和“星期中的日期”这两个元素是互斥的，因此应该通过设置一个问号（？）来表明你不想设置的那个字段。表7.1中显示了一些cron表达式的例子和它们的意义： 表达式 意义 “0 0 12 ?” 每天中午12点触发 “0 15 10 ? “ 每天上午10:15触发 “0 15 10 ?” 每天上午10:15触发 “0 15 10 ? *” 每天上午10:15触发 “0 15 10 ? 2005” 2005年的每天上午10:15触发 “0 14 * ?” 在每天下午2点到下午2:59期间的每1分钟触发 “0 0/5 14 ?” 在每天下午2点到下午2:55期间的每5分钟触发 “0 0/5 14,18 ?” 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发 “0 0-5 14 ?” 在每天下午2点到下午2:05期间的每1分钟触发 “0 10,44 14 ? 3 WED” 每年三月的星期三的下午2:10和2:44触发 “0 15 10 ? * MON-FRI” 周一至周五的上午10:15触发 “0 15 10 15 * ?” 每月15日上午10:15触发 “0 15 10 L * ?” 每月最后一日的上午10:15触发 “0 15 10 ? * 6L” 每月的最后一个星期五上午10:15触发 “0 15 10 ? * 6L 2002-2005” 2002年至2005年的每月的最后一个星期五上午10:15触发 “0 15 10 ? * 6#3” 每月的第三个星期五上午10:15触发]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud配置中心————Spring Cloud Config]]></title>
    <url>%2F2018%2F08%2F07%2FSpring-Cloud%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E2%80%94%E2%80%94Spring-Cloud-Config%2F</url>
    <content type="text"><![CDATA[前言似乎从接触计算机编程开始就被告知，不要把程序配置信息硬编码进代码。这自然是有道理的，如果配置信息硬编码进代码，一旦参数发生改变那么是必要对程序进行重新编译，所以才有了后来的配置文件与代码完全分离的方式。我们会把相关配置集中的写在一个配置文件中，这样我们可以在不重新编译代码的情况下实现配置的更改。这种方式适用于少量的应用程序，在微服务大行其道的今天如果还是采用这种方式那么很可能会把运维给逼疯、、、试想一下一个应用程序有100个微服务构成（一点也不夸张）每个服务都有多个实例，如果还是用上面这种方式的话光配置文件就得有几千个…在微服务中主要通过4条原则来约束应用程序的配置管理： 分离——服务配置信息与服务的实际物理部署完全分离开。应用程序的配置不应与服务实例一起部署。相反，配置信息应该作为环境变量传递给正在启动的服务，或者在服务启动时从集中式存储中读取 抽象——将访问配置数据的功能抽象到一个借口服务中。 集中——将应用程序配置集中在尽可能少的存储库中 稳定——高可用]]></content>
      <categories>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+github pages博客之路起航]]></title>
    <url>%2F2018%2F07%2F31%2Fhexo-github-pages%E5%8D%9A%E5%AE%A2%E4%B9%8B%E8%B7%AF%E8%B5%B7%E8%88%AA%2F</url>
    <content type="text"><![CDATA[前言 喜欢写Blog的人，会经历三个阶段。————阮一峰 123- 第一阶段，刚接触Blog，觉得很新鲜，试着选择一个免费空间来写。- 第二阶段，发现免费空间限制太多，就自己购买域名和空间，搭建独立博客。- 第三阶段，觉得独立博客的管理太麻烦，最好在保留控制权的前提下，让别人来管，自己只负责写文章。 由于平时比较懒所以第一、第二阶段虽然都经历过但都没坚持下来（理由吗、、、有很多），平时更多的是通过印象笔记之类的进行知识梳理及记录，但这种三方记录软件存在太多的限制，机缘巧合下遇上了hexo，擦！这不是就是我要找的吗，赶紧拿来学习！说来也惭愧用了这么多年的github直到今天才知道github pages的存在“众里寻他千百度，蓦然回首那人却在灯火阑珊处”说的就是我此时的心情吧。 网上对于如何使用hexo结合github pages搭建私有博客已经有很多教程，本文的目的只是做些简要的记录不做详细说明。对于_config.yml的说明：hexo的位于根目录下站点配置文件，主题配置文件在对应的主题目录下 GitHub Pages Github Pages 是面向用户、组织和项目开放的公共静态页面搭建托管服务，站点可以被免费托管在 Github 上，你可以选择使用 Github Pages 默认提供的域名 github.io 或者自定义域名来发布站点。Github Pages 支持 自动利用 Jekyll 生成站点，也同样支持纯 HTML 文档，将你的 Jekyll 站 点托管在 Github Pages 上是一个不错的选择。 其实对于github pages的创建没什么可说的只需要创建一个“账号名+github.io”的仓库即可。创建完成后即可通过https://cjlovepp.github.io进行访问。 hexo安装配置要使用Hexo，需要在你的系统中支持Nodejs以及Git，如果还没有，ennnnn~~~装呗！ 安装Node.js安装Git安装Hexo关于Hexo的详细使用说明文档参考：https://hexo.io/zh-cn/docs/commands 创建一个空的文件夹（该文件夹用于站点的发布，所以最好不要随便放） Git Bash进入之前创建的目录 12345npm install hexo-cli -g hexo init #初始化网站 npm install hexo g #生成或 hexo generate hexo s #启动本地服务器 或者 hexo server,这一步之后就可以通过http://localhost:4000 查看了 部署到GitHub通过设置”_config.yml”文件中的deploy来配置githup仓库地址，github提交时支持用户名密码和SSH Key两种方式,这里介绍SSH的配置方式 检查SSH keys设置进入git bash123456cd ~/.sshls#如果文件存在直接打开`*.pub`复制内容即可，如果没有则自己生成一个ssh-keygen -t rsa -C "邮件地址@youremail.com" #生成新的key文件,邮箱地址填你的Github地址#Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa):&lt;回车就好&gt;#接下来会让你输入密码（直接回车也可以） 添加SSH Key到Github进入github首页找到对应的repository，进入setting将key添加到deploy keys中。123#测试是否成功ssh -T git@github.com#之后会要你输入yes/no,输入yes就好了。 部署到github1hexo d 没错，就是这么简单。结束！ 补充图片存储解决写技术类文章没有图片怎么行？一张到位的图片能省去大篇幅的文字说明（还不一定说的清），所以博客中插入图片便成了刚需，那么问题来了图片存哪合适呢？网上通用的解决方案 七牛云 我也曾用过一段时间，说实在的问题是解决了但体验并不是很好（每次要把图片先上传到七牛的服务器然后再使用），所以果断放弃！在hexo发展至今都没有一个好的图片解决方案？开什么玩笑—-hexo-asset-image，对喽就是这货，来看看具体怎么用吧。 首先确认_config.yml 中开启 post_asset_folder:true。Hexo 提供了一种更方便管理 Asset 的设定：post_asset_folder当您设置post_asset_folder为true参数后，在建立文件时，Hexo会自动建立一个与文章同名的文件夹，您可以把与该文章相关的所有资源都放到那个文件夹，如此一来，您便可以更方便的使用资源。 安装 hexo-asset-image 1npm install hexo-asset-image --save 完成安装后用hexo新建文章的时候会发现_posts目录下面会多出一个和文章名字一样的文件夹。图片就可以放在文件夹下面。结构如下： 12345本地图片测试├── apppicker.jpg├── logo.jpg└── rules.jpg本地图片测试.md 这样的目录结构（目录名和文章名一致），只要使用 ![logo](本地图片测试/logo.jpg) 就可以插入图片。生成的结构为12345public/2016/3/9/本地图片测试├── apppicker.jpg├── index.html├── logo.jpg└── rules.jpg 同时，生成的 html 是 1&lt;img src="/2016/3/9/本地图片测试/logo.jpg" alt="logo"&gt; 而不是1&lt;img src="本地图片测试/logo.jpg" alt="logo"&gt; 这种方式存在一个明显的弊端就是随着使用git会越来越大，但就目前我的需求来讲暂时不用考虑这些问题 hexo主题配置hexo只是很多主题获取主题的方式当然是通过官网 主题，如何启用主题都有对应的说明此处不多废话，进过精挑细后还是觉定采用社区比较认可的NexT,详细的使用说明可以参考 中文文档 hexo插件可以去 插件 找到很多有用的插件 添加【分类，标签】等功能hexo可以对博客进行标签分类，侧边栏添加并实现分类和标签功能的做法类似，这里以分类为例 创建分类显示页面1hexo new page categories 你会发现你的source文件夹下有了categorcies/index.md，之所以命名为categories的原因是在next主题的配置文件中，categories是关键词。 编辑新建界面，将页面类型设置为categories，主题将会在这个页面上显示所有的分类：12345---title: categoriesdate: 2018-03-02 12:33:16type: "categories" //这点尤为重要否则分类页是空的--- 另外就是，需要注意一点：如果有启用多说 或者 Disqus 评论，默认页面也会带有评论。需要关闭的话，请添加字段 comments 并将值设置为 false，如：123456---title: categoriesdate: 2018-03-02 12:33:16type: "categories"comments: false--- 在菜单中添加链接，此时需要编辑主题的_config.yml，hexo的配置文件事先写好了，但是处于注释状态，需要去除注释即可： 123456menu: home: / || home about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive 添加文章分类关联把文章归入分类只需在文章的顶部标题下方添加categories字段，即可自动创建分类名并加入对应的分类中： 12345678---title: hexo+github pages博客之路起航date: 2018-07-31 17:08:10tags: - hexo - github pagescategories: hexo--- 添加搜索 1、安装 hexo-generator-searchdb 插件 1$ npm install hexo-generator-searchdb --save 2、打开 站点配置文件` 找到Extensions在下面添加 123456# 搜索search: path: search.xml field: post format: html limit: 10000 3、打开 主题配置文件` 找到Local search，将enable设置为true 添加阅读全文按钮因为在你的博客主页会有多篇文章，如果你想让你的文章只显示一部分，多余的可以点击阅读全文来查看，那么你需要在你的文章中添加1&lt;!--more--&gt; 其后面的部分就不会显示了，只能点击阅读全文才能看 提交hexo源码到githubhexo在将网站发布到github时只是将生成的静态页同步到github中，而编写的文件源码（xxx.md）并不会上传到git。这样的话当我们数据损坏或者需要在别的地方编写时就会很尴尬。所以最好的方式是我们把hexo源代码也上传到github中。 建立分支：因为 master 分支是存放 Hexo 博客生成的页面，所以只能创建一个分支来保存博客的源代码在你的 GitHub 设置默认分支为 hexo这里需要有注意站点配置文件 _config.yml 的 deploy 需要设置成 master OK，提交到代码到 hexo 分支即可 添加背景图片给hexo next添加背景图片，只需要在 themes\next\source\css\_custom\custom.styl 添加如下代码即可：12345678910111213@media screen and (min-width:1200px) &#123; body &#123; background-image:url(/images/background.jpg); background-repeat: no-repeat; background-attachment:fixed; background-position:50% 50%; &#125; #footer a &#123; color:#eee; &#125;&#125; 字数统计用于统计文章的字数以及分析出阅读时间。 添加hexo-wordcount插件 1npm install hexo-wordcount --save 在主题配置文件中，搜索wordcount，设置为下面这样就可以了： 123456post_wordcount: item_text: true wordcount: true min2read: true totalcount: true separated_meta: true 再打开\themes\next\layout\_macro\post.swig 文件，在leancloud-visitors-count后面位置添加一个分割符： 1234 &lt;span class=&quot;leancloud-visitors-count&quot;&gt;&lt;/span&gt; &lt;/span&gt; &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt;&#123;% endif %&#125; 自动部署到github pages]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
