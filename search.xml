<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[视频格式基础知识]]></title>
    <url>%2F2019%2F01%2F10%2F%E8%A7%86%E9%A2%91%E6%A0%BC%E5%BC%8F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[前言 对于一个电影爱好者来说，看到各种带4K、2160p、10bit这种字眼的视频文件总是想着去下下来收藏起来。最近也尝试着接触各种PT站（以前不去尝试主要是因为，家里带宽不稳定，PT账号得来不易啊~~~）。但对于各种视频文件名总是不明其意，只是单纯的通过1080p，2160p这些关键信息来判断媒体文件的收藏价值，对于H264、H265这些更是一脸懵逼。所以决定学习扫盲下，不求深入，只求以后能在看到这些文件的时候能大致知道怎么回事就行。 封装格式(MP4/MKV…) VS 媒体格式(H.264/FLAC/AAC…)MP4+MKV是你下载的视频文件最常见的种类。这些文件其实类似一个包裹，它的后缀则是包裹的包装方式。这些包裹里面，包含了视频（只有图像），音频（只有声音），字幕等。当播放器在播放的时候，首先对这个包裹进行拆包（专业术语叫做分离/splitting）,把其中的视频、音频等拿出来，再进行播放。 既然它们只是一个包裹，就意味着这个后缀不能保证里面的东西是啥，也不能保证到底有多少东西。包裹里面的每一件物品，我们称之为轨道(track)，一般有这么些： 视频(Video):一般来说肯定都有，但是也有例外，比如mka格式的外挂音轨，其实就是没视频的mkv。注意我们说到视频的时候，是不包括声音的。 音频(audio)：一般来说也肯定有，但是有些情况是静音的，就没必要带了。 章节(Chapter): 蓝光原盘中自带的分段信息。如果文件带上了，那么你可以在播放器中看到带章节的效果： potplayer右键画面，选项-播放-在进度条上显示书签/章节标记 mpc-hc 右键画面，选项-调节-在进度条显示章节标记 字幕(Subtitles)：有些时候文件自带字幕，并且字幕并非是直接整合于视频的硬字幕，那么就是一起被打包在封装容器中。 其他可能还有附件等，不一一列举。每个类型也不一定只有一条轨道，比如经常见到带多音轨的MKV。 每个轨道，都有自己的格式。比如大家常说的，视频是H.264，音频是AAC，这些就是每个轨道的格式。 视频的格式，常见的有H.264(可以细分为8bit/10bit)，H.265(当前也有8bit/10bit之分)，RealVideo(常见于早期rm/rmvb)，VC-1(微软主导的，常见于wmv)。基本上，H.264=AVC=AVC1, H.265=HEVC。 音频的格式，常见的有 FLAC/ALAC/TrueHD/DTS-HD MA这四种无损，和AAC/MP3/AC3/DTS(Core)这四种有损。 MKV vs MP4，主要的区别在于： MKV支持封装FLAC作为音频，MP4则不支持。但是MP4也可以封装无损音轨(比如说ALAC，虽然普遍认为ALAC的效率不如FLAC优秀) MKV支持封装ASS/SSA格式的字幕，MP4则不支持。一般字幕组制作的字幕是ASS格式，所以内封字幕多见于MKV格式 MP4作为工业标准，在视频编辑软件和播放设备上的兼容性一般好于MKV。这也是vcb-s那些为移动设备优化的视频基本上选择MP4封装的原因。 除此之外，这两个格式很大程度上可以互相代替。比如它们都支持封装AVC和HEVC，包括8bit/10bit的精度。所以MP4画质不如MKV好，这种论断是非常无知的——它们完全可以封装一样的视频。 为什么会有这样的分歧，就是历史原因了。MKV是民间研发，为了代替古老的AVI，从而更好地支持H264，它开发和修改的灵活度使得它可以兼容flac/ass这类非工业标准的格式；而MP4则是出生豪门，作为工业标准，替代更古老的MPG，作为新一代视频/音频封装服务的。 视频的基础参数：分辨率，帧率和码率 分辨率：视频是由连续的图像构成的。每一张图像，我们称为一帧(frame)。图像则是由像素(pixel)构成的。一张图像有多少像素，称为这个图像的分辨率。比如说1920×1080的图像，说明它是由横纵1920×1080个像素点构成。视频的分辨率就是每一帧图像的分辨率。 帧率：一个视频，每一秒由多少图像构成，称为这个视频的帧率(frame-rate)。常见的帧率有24000/1001=23.976, 30000/1001=29.970, 60000/1001=59.940, 25.000,50.000等等。这个数字是一秒钟内闪过的图像的数量。比如23.976，就是1001秒内，有24000张图像。视频的帧率是可以是恒定的(cfr, Const Frame-Rate)，也可以是变化的(vfr, Variable Frame-Rate) 码率：码率的定义是视频文件体积除以时间。单位一般是Kbps(Kbit/s)或者Mbps(Mbit/s)。注意1B(Byte)=8b(bit)。所以一个24分钟，900MB的视频： 12345体积：900MB = 900MByte = 7200Mbit时间：24min = 1440s码率：7200/1440 = 5000 Kbps = 5Mbps 当视频文件的时间基本相同的时候（比如现在一集番大概是24分钟），码率和体积基本上是等价的，都是用来描述视频大小的参数。长度分辨率都相同的文件，体积不同，实际上就是码率不同。 码率也可以解读为单位时间内，用来记录视频的数据总量。码率越高的视频，意味着用来记录视频的数据量越多，潜在的解读就是视频可以拥有更好的质量。（注意，仅仅是潜在，后文我们会分析为什么高码率不一定等于高画质） 色深色深(bit-depth)，就是我们通常说的8bit和10bit，是指每个通道的精度。8bit就是每个通道用一个8bit整数(0~255)代表，10bit就是用10bit整数(0~1023)来显示。16bit则是0~65535 (注意，上文的表述是不严谨的，视频在编码的时候，并非一定能用到0~255的所有范围，而是可能有所保留，只用到一部分，比如16~235。这我们就不详细展开了) 你的显示器是8bit的，代表它能显示RGB每个通道0~255所有强度。但是视频的色深是YUV的色深，播放的时候，YUV需要通过计算转换到RGB。因此，10bit的高精度是间接的，它使得运算过程中精度增加，以让最后的颜色更细腻。 如何理解8bit显示器，播放10bit是有必要的呢： 一个圆的半径是12.33m, 求它的面积，保留两位小数。 半径的精度给定两位小数，结果也要求两位小数，那么圆周率精度需要给多高呢？也只要两位小数么？取pi=3.14, 面积算出来是477.37平方米取pi=3.1416，面积算出来是477.61平方米取pi精度足够高，面积算出来是477.61平方米。所以取pi=3.1416是足够的，但是3.14就不够了。 换言之，即便最终输出的精度要求较低，也不意味着参与运算的数字，以及运算过程，可以保持较低的精度。在最终输出是8bit RGB的前提下，10bit YUV比起8bit YUV依旧具有精度优势的原因就在这里。事实上，8bit YUV转换后，覆盖的精度大概相当于8bit RGB的26%，而10bit转换后的精度大约可以覆盖97%——你想让你家8bit显示器发挥97%的细腻度么？看10bit吧。 8bit精度不足，主要表现在亮度较低的区域，容易形成色带：注意这图右边那一圈圈跟波浪一样的效果。这就是颜色精度不足的表现。 10bit的优势不只在于显示精度的提高，在提高视频压缩率，减少失真方面，相对8bit也有优势。这方面就不展开了。 图像的表示方法：RGB模型 vs YUV模型光的三原色是红(Red)、绿(Green)、蓝(Blue)。现代的显示器技术就是通过组合不同强度的三原色，来达成任何一种可见光的颜色。图像储存中，通过记录每个像素红绿蓝强度，来记录图像的方法，称为RGB模型 (RGB Model) 常见的图片格式中，PNG和BMP这两种就是基于RGB模型的。 比如说原图：分别只显示R G B通道的强度，效果如下：三个通道下，信息量和细节程度不一定是均匀分布的。比如说可以注意南小鸟脸上的红晕，在3个平面上的区分程度就不同——红色平面下几乎无从区分，造成区别的主要是绿色和蓝色的平面。外围白色的脸颊，三色都近乎饱和；但是红晕部分，只有红色饱和，绿色和蓝色不饱和。这是造成红色凸显的原因。 除了RGB模型，还有一种广泛采用的模型，称为YUV模型，又被称为亮度-色度模型（Luma-Chroma）。它是通过数学转换，将RGB三个通道，转换为一个代表亮度的通道(Y,又称为Luma)，和两个代表色度的通道(UV，并成为Chroma)。 举个形象点的例子：一家养殖场饲养猪和牛，一种记数方式是：（猪的数量，牛的数量） 但是也可以这么记录：（总数量=猪的数量+牛的数量，相差=猪的数量-牛的数量）。两种方法之间有数学公式可以互转。 YUV模型干的是类似的事儿。通过对RGB数据的合理转换，得到另一种表示方式。YUV模型下，还有不同的实现方式。举个用的比较多的YCbCr模型：它把RGB转换成一个亮度(Y)，和 蓝色色度(Cb) 以及 红色色度(Cr)。转换背后复杂的公式大家不需要了解，只需要看看效果： 只有亮度通道：只有蓝色色度：只有红色色度：在图像视频的加工与储存中，YUV格式一般更受欢迎，理由如下： 1、人眼对亮度的敏感度远高于色度，因此人眼看到的有效信息主要来自于亮度。YUV模型可以将绝大多数的有效信息分配到Y通道。UV通道相对记录的信息少的多。相对于RGB模型较为平均的分配，YUV模型将多数有效信息集中在Y通道，不但减少了冗余信息量，还为压缩提供了便利 2、保持了对黑白显示设备的向下兼容 3、图像编辑中，调节亮度和颜色饱和度，在YUV模型下更方便。 几乎所有的视频格式，以及广泛使用的JPEG图像格式，都是基于YCbCr模型的。播放的时候，播放器需要将YCbCr的信息，通过计算，转换为RGB。这个步骤称为渲染（Rendering） 每个通道的记录，通常是用整数来表示。比如RGB24，就是RGB各8个bit，用0~255 (8bit的二进制数范围)来表示某个颜色的强弱。YUV模型也不例外，也是用整数来表示每个通道的高低。 色度半采样在YUV模型的应用中，Y和UV的重要性是不等同的。图像视频的实际储存和传输中，通常将Y以全分辨率记录，UV以减半甚至1/4的分辨率记录。这个手段被称为色度半采样(Chroma Sub-Sampling)。色度半采样可以有效减少传输带宽，和加大UV平面的压缩率，但是不可避免的会损失UV平面的有效信息。 我们平常的视频，最常见的是420采样。配合YUV格式，常常被写作yuv420。这种采样是Y保留全部，UV只以(1/2) x (1/2)的分辨率记录。比如说1920×1080的视频，其实只有亮度平面是1920×1080。两个色度平面都只有960×540的分辨率。 当然了，你也可以选择不做缩减。这种称为444采样，或者yuv444。YUV三个平面全是满分辨率。 在做YUV-&gt;RGB的时候，首先需要将缩水的UV分辨率拉升到Y的分辨率（madVR中允许自定义算法，在Chroma Upscaling当中），然后再转换到RGB。做RGB-&gt;YUV的转换，也是先转换到444（YUV的分辨率相同），再将UV分辨率降低。 一般能拿到的片源，包括所有蓝光原盘，都是420采样的。所以成品一般也保留420采样。所以yuv420就表示这个视频是420采样的yuv格式。 将420做成444格式，需要自己手动将UV分辨率拉升2×2倍。在今天madVR等渲染器可以很好地拉升UV平面的情况下，这种做法无异于毫无必要的拉升DVD做成伪高清。 当然了，有时候也需要在444/RGB平面下做处理和修复，常见的比如视频本身RGB平面不重叠（比如摩卡少女樱），这种修复过程首先要将UV分辨率拉升，然后转RGB，做完修复再转回YUV。修复后的结果相当于全新构图，这种情况下保留444格式就是有理由，有必要的。 H264格式编码444格式，需要High 4:4:4 Predictive Profile（简称Hi444pp）。所以看到Hi444pp/yuv444 之类的标示，你就需要去找压制者的陈述，为什么他要做这么个拉升。如果找不到有效的理由，你应该默认作者是在瞎做。 空间上的低频与高频：平面，纹理和线条在视频处理中，空间(spatial)的概念指的是一帧图片以内（你可以认为就是一张图所呈现的二维空间/平面）。跟时间(temporal)相对；时间的概念就强调帧与帧之间的变换。 于是我们重新来看这张亮度的图：亮度变化较快，变动幅度大的区域，我们称之为高频区域。否则，亮度变化缓慢且不明显的区域，我们称为低频区域。 图中的蓝圈就是一块典型的低频区域，或者就叫做平面（平坦的部分）。亮度几乎没有变化 绿圈中，亮度呈现跳跃式的突变，这种高频区域我们称之为线条。 红圈中，亮度频繁变化，幅度有高有低，这种高频区域我们称为纹理。 有时候，线条和纹理（高频区域）统称为线条，平面（低频区域）又叫做非线条。 这是亮度平面。色度平面，高频低频，线条等概念也同样适用，就是描述色度变化的快慢轻重。一般我们所谓的“细节”，就是指图像中的高频信息。 一般来说，一张图的高频信息越多，意味着这张图信息量越大，所需要记录的数据量就越多，编码所需要的运算量也越大。如果一个视频包含的空间性高频信息很多（通俗点说就是每一帧内细节很多），意味着这个视频的空间复杂度很高。 记录一张图片，编码器需要决定给怎样的部分多少码率。码率在一张图内不同部分的分配，叫做码率的空间分配。分配较好的时候，往往整幅图目视观感比较统一；分配不好常见的后果，就是线条纹理尚可，背景平面区域出现大量色带色块（码率被过分的分配给线条）；或者背景颜色过渡自然，纹理模糊，线条烂掉（码率被过分的分配给非线条）。 时间上的低频与高频：动态在视频处理中，时间(temporal)的概念强调帧与帧之间的变换。跟空间(spatial)相对。 动态的概念无需多解释；就是帧与帧之间图像变化的强弱，变化频率的高低。一段视频如果动态很高，变化剧烈，我们称为时间复杂度较高，时域上的高频信息多。否则如果视频本身舒缓多静态，我们称为时间复杂度低，时域上的低频信息多。 一般来说，一段视频的时域高频信息多，动态的信息量就大，所需要记录的数据量就越多，编码所需要的运算量也越大。但是另一方面，人眼对高速变化的场景，敏感度不如静态的图片来的高（你没有时间去仔细观察细节），所以动态场景的优先度可以低于静态场景。如何权衡以上两点去分配码率，被称为码率的时间分配。分配较好的时候，看视频无论动态还是静态效果都较好；分配不好的时候往往是静态部分看着还行，动态部分糊烂掉；或者动态部分效果过分的好，浪费了大量码率，造成静态部分欠码，瑕疵明显。 很多人喜欢看静止的截图对比，来判断视频的画质。从观看的角度，这种做法其实并不完全科学——如果你觉得比较烂的一帧其实是取自高动态场景，那么这一帧稍微烂点无可厚非，反正观看的时候你注意不到，将码率省下来给静态部分会更好。 清晰度与画质简述我们经常讨论，一个视频清晰度如何，画质好不好。但是如何给这两个术语做定义呢？ 经常看到的说法：“这个视频清晰度是1080p的”。其实看过上文你就应该知道，1080p只是视频的分辨率，它不能直接代表清晰度——比如说，我可以把一个480p的dvd视频拉升到1080p，那又怎样呢？它的清晰度难道就提高了么？ 一个比较接近清晰度的概念，是上文所讲述的，空间高频信息量，就是一帧内的细节。一张图，一个视频的细节多，它的清晰度就高。分辨率决定了高频信息量的上限；就是它最清晰能到什么地步。1080p之所以比480p好，是因为它可以允许图像记录的高频信息多。这个说法看样子很靠谱，但是，有反例：右图的高频信息远比左图多——它的线条很锐利，有大量致密的噪点（注意噪点完全符合高频信息的定义；它使得图像变化的非常快）但是你真的觉得右图清晰度高么？事实上，右图完全是通过左图加工而来。通过过度锐化+强噪点，人为的增加无效的高频信息。 所以清晰度的定义我更倾向于这样一个说法：图像或视频中，原生、有效的高频信息。原生，强调这种清晰度是非人工添加的；有效；强调细节本身有意义，而不是毫无意义的噪点特效。 值得一提的是，人为增加的高频信息不见得完全没有帮助。有的时候适度锐化的确能够起到不错的目视效果：这是一幅适度锐化后的效果。如果有人觉得右图更好，至少某些部分更好，相信我，你不是一个人。所以适度锐化依旧是视频和图像处理中，可以接受的一种主观调整的手段，一定的场合下，它确实有助于提高目视效果。 以上是清晰度的概述。注意，清晰度只是空间方面（就是一帧以内）。如果再考虑到动态效果的优秀与否（视频是不是那种一动起来就糊成一团的，或者动起来感觉卡顿明显的，常见于早起RMVB），空间和时间上优秀的观看效果共同定义了画质。所以我们说madVR/svp那些倍帧效果有助于提高画质，实际上它们增强了时间上的观看效果。 好的画质，是制作者和观众共同追求的。怎么样的视频会有好的画质呢？是不是码率越高的视频画质越好呢？真不见得。视频的画质，是由以下几点共同决定的： 1、源的画质。俗话说的好，上梁不正下梁歪。如果源的画质本身很差，那么再如何折腾都别指望画质好到哪去。所以压制者往往会选择更好的源进行压制——举个栗子，BDRip一般都比TVRip来的好，哪怕是720p。蓝光也分销售地区，一般日本销售的日版，画质上比美版、台版、港版啥的都来得好，所以同样是BDRip，选取更好的源，就能做到画质上优先一步。 2、播放条件。观众是否用了足矣支持高画质播放的硬件和软件。这就是为啥我们在发布Rip的同时大力普及好的播放器；有时候一个好的播放器胜过多少在制作方面的精力投入。 3、码率投入vs编码复杂度。视频的时间和空间复杂度，并称为编码复杂度。编码复杂度高的视频，往往细节多，动态高（比如《魔法少女小圆剧场版 叛逆的物语》），这样的视频天生需要较高的码率去维持一个优秀的观看效果。相反，有些视频编码复杂度低（比如《请问今天要来点兔子么》，动态少，线条细节柔和），这种视频就是比较节省码率的。 4、码率分配的效率和合理度。同样多的码率，能起到怎样好的效果，被称为效率。比如H264就比之前的RealVideo效率高；10bit比8bit效率高；编码器先进，参数设置的比较合理，编码器各种高端参数全开（通常以编码时间作为代价），码率效率就高。合理度就是码率在时空分配方面合理与否，合理的分配，给观众的观看效果就比较统一协调。 码率分配的效率和合理度，是对制作者的要求，要求制作者对片源分析，参数设置有比较到位的理解。 参考 视频格式基础知识：让你了解MKV、MP4、H.265、码率、色深等等…]]></content>
      <categories>
        <category>4K</category>
      </categories>
      <tags>
        <tag>4K</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis-jedis使用管道(pipeline)]]></title>
    <url>%2F2018%2F08%2F22%2Fredis-jedis%E4%BD%BF%E7%94%A8%E7%AE%A1%E9%81%93-pipeline%2F</url>
    <content type="text"><![CDATA[前言Redis的pipeline(管道)功能在命令行中没有，但redis是支持pipeline的，而且在各个语言版的client中都有相应的实现。 由于网络开销延迟，就算redis server端有很强的处理能力，也会由于收到的client消息少，而造成吞吐量小。当client 使用pipelining 发送命令时，redis server必须将部分请求放到队列中（使用内存），执行完毕后一次性发送结果；如果发送的命令很多的话，建议对返回的结果加标签，当然这也会增加使用的内存； Pipeline在某些场景下非常有用，比如有多个command需要被“及时的”提交，而且他们对相应结果没有互相依赖，对结果响应也无需立即获得，那么pipeline就可以充当这种“批处理”的工具；而且在一定程度上，可以较大的提升性能，性能提升的原因主要是TCP连接中减少了“交互往返”的时间。 不过在编码时请注意，pipeline期间将“独占”链接，此期间将不能进行非“管道”类型的其他操作，直到pipeline关闭；如果你的pipeline的指令集很庞大，为了不干扰链接中的其他操作，你可以为pipeline操作新建Client链接，让pipeline和其他正常操作分离在2个client中。不过pipeline事实上所能容忍的操作个数，和socket-output缓冲区大小/返回结果的数据尺寸都有很大的关系；同时也意味着每个redis-server同时所能支撑的pipeline链接的个数，也是有限的，这将受限于server的物理内存或网络接口的缓冲能力。 原理说明Redis使用的是客户端-服务器（CS）模型和请求/响应协议的TCP服务器。这意味着通常情况下一个请求会遵循以下步骤： 客户端向服务端发送一个查询请求，并监听Socket返回，通常是以阻塞模式，等待服务端响应。 服务端处理命令，并将结果返回给客户端。 Redis客户端与Redis服务器之间使用TCP协议进行连接，一个客户端可以通过一个socket连接发起多个请求命令。每个请求命令发出后client通常会阻塞并等待redis服务器处理，redis处理完请求命令后会将结果通过响应报文返回给client，因此当执行多条命令的时候都需要等待上一条命令执行完毕才能执行。其执行过程如下图： 由于通信会有网络延迟，假如client和server之间的包传输时间需要0.125秒。那么上面的三个命令6个报文至少需要0.75秒才能完成。这样即使redis每秒能处理100个命令，而我们的client也只能一秒钟发出四个命令。这显然没有充分利用 redis的处理能力。 而管道（pipeline）可以一次性发送多条命令并在执行完后一次性将结果返回，pipeline通过减少客户端与redis的通信次数来实现降低往返延时时间，而且Pipeline 实现的原理是队列，而队列的原理是时先进先出，这样就保证数据的顺序性。 Pipeline 的默认的同步的个数为53个，也就是说arges中累加到53条数据时会把数据提交。其过程如下图所示：client可以将三个命令放到一个tcp报文一起发送，server则可以将三条命令的处理结果放到一个tcp报文返回。需要注意到是用 pipeline方式打包命令发送，redis必须在处理完所有命令前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并不是打包的命令越多越好。具体多少合适需要根据具体情况测试。 Jedis演示使用Pipeline在对Redis批量读写的时候，性能上有非常大的提升。使用Java测试了一下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import java.util.HashMap;import java.util.Map;import java.util.Set;import redis.clients.jedis.Jedis;import redis.clients.jedis.Pipeline;import redis.clients.jedis.Response;public class Test &#123; public static void main(String[] args) throws Exception &#123; Jedis redis = new Jedis("127.0.0.1", 6379, 400000); Map&lt;String, String&gt; data = new HashMap&lt;String, String&gt;(); redis.select(8); redis.flushDB(); // hmset long start = System.currentTimeMillis(); // 直接hmset for (int i = 0; i &lt; 10000; i++) &#123; data.clear(); data.put("k_" + i, "v_" + i); redis.hmset("key_" + i, data); &#125; long end = System.currentTimeMillis(); System.out.println("dbsize:[" + redis.dbSize() + "] .. "); System.out.println("hmset without pipeline used [" + (end-start)/1000 + "] seconds .."); redis.select(8); redis.flushDB(); // 使用pipeline hmset Pipeline p = redis.pipelined(); start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000; i++) &#123; data.clear(); data.put("k_" + i, "v_" + i); p.hmset("key_" + i, data);//将命令缓存起来 &#125; p.sync();//一次性提交所有命令 end = System.currentTimeMillis(); System.out.println("dbsize:[" + redis.dbSize() + "] .. "); System.out.println("hmset with pipeline used [" + (end-start)/1000 + "] seconds .."); // hmget Set keys = redis.keys("*"); // 直接使用Jedis hgetall start = System.currentTimeMillis(); Map&lt;String, Map&lt;String, String&gt;&gt; result = new HashMap&lt;String, Map&lt;String, String&gt;&gt;(); for (String key : keys) &#123; result.put(key, redis.hgetAll(key)); &#125; end = System.currentTimeMillis(); System.out.println("result size:[" + result.size() + "] .."); System.out.println("hgetAll without pipeline used [" + (end-start)/1000 + "] seconds .."); // 使用pipeline hgetall Map&lt;String, Response&lt;Map&lt;String, String&gt;&gt;&gt; responses = new HashMap&lt;String, Response&lt;Map&lt;String, String&gt;&gt;&gt;(keys.size()); result.clear(); start = System.currentTimeMillis(); for (String key : keys) &#123; responses.put(key, p.hgetAll(key));//缓存命令，并将结果集放入到responses中，注意，这里并没有正在返回结果 &#125; p.sync();//提交所有指令 for (String k : responses.keySet()) &#123;//一次性获取结果，因为pipeline是基于队列的所以顺序也能得到保障 result.put(k, responses.get(k).get()); &#125; end = System.currentTimeMillis(); System.out.println("result size:[" + result.size() + "] .."); System.out.println("hgetAll with pipeline used [" + (end-start)/1000 + "] seconds .."); redis.disconnect(); &#125;&#125; 测试结果：123456789//使用pipeline来批量读写10000条记录，就是小菜一碟，秒完。dbsize:[10000] ..hmset without pipeline used [243] seconds ..dbsize:[10000] ..hmset with pipeline used [0] seconds ..result size:[10000] ..hgetAll without pipeline used [243] seconds ..result size:[10000] ..hgetAll with pipeline used [0] seconds .. pipeline源码解读Pipeline类的结构 Jedis的Pipeline的实现看下上面的使用例子123456Pipeline p = redis.pipelined();....for()&#123; p.hmset("key_" + i, data);//将命令缓存起来&#125;p.sync(); 获取Pipeline对象BinaryJedis有一个成员变量pipeline，通过其pipeline()方法可以获取Pipeline对象 对的，就是它 pipeline()方法就干了一件事情，new了一个Pipeline对象，并设置了该对象的client属性！ Pipeline对象set方法干了啥pipeline的set方法实际调用的是Pipelinebase类（Pipeline父类的父类）的set方法：而getClient调用子类的实现： 调用client的set操作调用client的set操作跟踪源码发现实际是调用了sendCommand(Command.SET,key,value)方法。注意了，所有的cmd与参数都写入了outputstream Jedis定义了自己的输入流与输出流，现在所有的commands都在outputstream里面了，但是还没有传到redis客户端 Pipeline对象sync方法干了啥在上面Pipelinebase的set方法的最后了，调了一个getResponse()方法。该方法相当于把每一次的请求操作加入到一个Queue里面，这个队列有啥用？先放在这里！来看一下万恶的sync（）方法，注意红色的部分： 这个getPipelinedResponseLength()就是获取刚才的那个Queue的长度； 看看getMany()方法，一上来就fush(),这下前面代码循环写入的那么多set命名全部传到redis server了！ ps:flush刷新此输出流并强制写出所有缓冲的输出字节。flush 的常规协定是：如果此输出流的实现已经缓冲了以前写入的任何字节，则调用此方法指示应将这些字节立即写入它们预期的目标。 generateResponse(o)就是拿到返回值了，sync是没有返回值的，syncAndReturnAll有返回值 适用场景有些系统可能对可靠性要求很高，每次操作都需要立马知道这次操作是否成功，是否数据已经写进redis了，那这种场景就不适合。 还有的系统，可能是批量的将数据写入redis，允许一定比例的写入失败，那么这种场景就可以使用了，比如10000条一下进入redis，可能失败了2条无所谓，后期有补偿机制就行了，比如短信群发这种场景，如果一下群发10000条，按照第一种模式去实现，那这个请求过来，要很久才能给客户端响应，这个延迟就太长了，如果客户端请求设置了超时时间5秒，那肯定就抛出异常了，而且本身群发短信要求实时性也没那么高，这时候用pipeline最好了。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境安装Postgresql]]></title>
    <url>%2F2018%2F08%2F16%2FLinux%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85Postgresql%2F</url>
    <content type="text"><![CDATA[前言 Linux版本：CentOS PostgresSQL版本：9.5.6 安装下载安装软件包可直接去官网下载，下载后直接找个目录放进去就行，我这边的目录为’/usr/lib/pg/‘ 注意：该目录不是安装目录，所以安装完成后即可删除 解压1tar -zxvf postgresql-9.5.6.tar.gz 编译安装12345./configuremakemake install ./configure是检查当前环境能否安装PG，同时也可以使用 ./configure --help查看参数命令 这里注意下--prefix=PREFIX该参数用于指定pg的安装目录，默认是/usr/local/pgsql这里我直接使用默认值。 ./configure检测可能会提示系统未安装gcc等lib库，根据提示安装即可 创建postgres用户posgresql默认使用postgres用户12345adduser postgresmkdir /usr/local/pgsql/datachown postgres /usr/local/pgsql/data 创建数据库 创建pgsql数据目录：mkdir /mydir/pgsql_data 给postgres用户添加访问权限：chown postgres /mydir/pgsql_data/ 切换到postgres用户来操作数据库，pgsql数据库就以postgres为默认用户，执行： su - postgres 切换。切换之后建议修改~/.bash_profile将pgsql的bin目录加至环境变量中，方便直接使用pgsql相关命令 初始化数据库：/usr/lib/pg/bin/initdb -D /mydir/pgsql_data/,执行结果如下说明成功 配置数据库配置远程访问需要修改两个配置文件postgresql.conf和pg_hba.conf 修改监听地址123#listen_addresses=’localhost’#将上面这行改成如下listen_addresses=’*’ 添加IP授权123# 这是在/pgsql/data/pg_hba.conf文件里加# IPv4 myhost connections:host all all 0.0.0.0/0 trust 这里设置了对所有IP开发，可修改trust为password为远程登录设置密码，重启后生效 启动/重启1bin/pg_ctl start -D /mount/pgsql_data/ -l /mount/pgsql_log //重启restart 设置远程登陆账户和密码服务器本地登陆postgresql数据库（默认是不需要密码的）1234567[postgres@localhost pgsql]$ pwd/usr/local/pgsql[postgres@localhost pgsql]$ bin/psqlpsql.bin (9.5.9)Type "help" for help. 创建角色，并且给角色设置密码: 123postgres=# create user testwjw with password 'Zykj@5&amp;^%996';CREATE ROLE 修改数据库用户和密码： 123postgres=# alter user testwjw with password '558996';ALTER ROLE 指定字符集创建数据库testdb1，并且授权给testwjw 123postgres=# create database testdb1 with encoding='utf8' owner=testwjw;CREATE DATABASE 授权： 123postgres=# grant all privileges on database testdb1 to testwjw; GRANT 修改postgresql.conf文件中的端口和监听主机:postsql默认安装后是监听本机127.0.0.1 默认端口是5432,是不能够远程登陆的，所以要修改监听主机地址postgresql数据库的配置文件是:postgresql.conf,所在位置是：postgresql初始化时所指定的data数据目录下：具体可参照上文的配置 重启postgresql服务生效：命令行下基础命令基础查看指令 连接数据库，默认的用户和数据库postgres: psql -U user -d dbname 切换数据库，相当于mysql的use dbname : \c dbname 列举数据库，相当于mysql的show databases： \l 列举表，相当于mysql的show tables ： \dt 查看表结构，相当于desc tblname,show columns from tbname ：\d tblname 查看索引 : \di 退出 psql: \q 数据库操作相关指令 创建数据库： create database [数据库名]; 删除数据库： drop database [数据库名]; *重命名一个表： alter table [表名A] rename to [表名B]; *删除一个表： drop table [表名]; *在已有的表里添加字段： alter table [表名] add column [字段名] [类型]; *删除表中的字段： alter table [表名] drop column [字段名]; *重命名一个字段：alter table [表名] rename column [字段名A] to [字段名B]; *给一个字段设置缺省值： alter table [表名] alter column [字段名] set default [新的默认值]; *去除缺省值：alter table [表名] alter column [字段名] drop default; 在表中插入数据： insert into 表名 ([字段名m],[字段名n],......) values ([列m的值],[列n的值],......); 修改表中的某行某列的数据： update [表名] set [目标字段名]=[目标值] where [该行特征]; 删除表中某行数据： delete from [表名] where [该行特征]; 删空整个表 : delete from [表名]; 创建表： create table ([字段名1] [类型1] ;,[字段名2] [类型2],......&lt;,primary key (字段名m,字段名n,...)&gt;;); 显示 PostgreSQL 的使用和发行条款 \copyright 显示或设定用户端字元编码: \encoding [字元编码名称] SQL 命令语法上的说明，用 * 显示全部命令 : \h [名称] 备份还原相关指令可以使用pg_dump和pg_dumpall来完成。比如备份sales数据库：pg_dump drupal&gt;/opt/Postgresql/backup/1.bak 删除库的时候报错12ERROR: database "temp_test_yang" is being accessed by other usersDETAIL: There are 4 other sessions using the database. 说明该temp_test_yang库正在被人连接。解决方法是：查询出连接该数据库的进程，并将其杀死(比较暴力)select pg_terminate_backend(pid) from pg_stat_activity where DATNAME = ‘temp_test_yang’;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java任务调度框架]]></title>
    <url>%2F2018%2F08%2F09%2FJava%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[前言在进行Web开发时，我们经常会遇到任务调度的需求，要求你在某个特定的时间段执行某个任务。这里对JAVA的几种任务调度的实现做下学习记录：Timer、ScheduleExecutor、Quartz、JCronTab。 Timerjava.util.Timer提供了一种简单的任务调度实现方法：123456789101112131415161718192021222324252627282930package com.ibm.scheduler; import java.util.Timer; import java.util.TimerTask; public class TimerTest extends TimerTask &#123; private String jobName = ""; public TimerTest(String jobName) &#123; super(); this.jobName = jobName; &#125; @Override public void run() &#123; System.out.println("execute " + jobName); &#125; public static void main(String[] args) &#123; Timer timer = new Timer(); long delay1 = 1 * 1000; long period1 = 1000; // 从现在开始 1 秒钟之后，每隔 1 秒钟执行一次 job1 timer.schedule(new TimerTest("job1"), delay1, period1); long delay2 = 2 * 1000; long period2 = 2000; // 从现在开始 2 秒钟之后，每隔 2 秒钟执行一次 job2 timer.schedule(new TimerTest("job2"), delay2, period2); &#125;&#125; 输出结果：123456execute job1 execute job1 execute job2 execute job1 execute job1 execute job2 使用 Timer 实现任务调度的核心类是 Timer 和 TimerTask。其中Timer负责设定TimerTask的起始与间隔执行时间。使用者只需要创建一个 TimerTask 的继承类，实现自己的 run 方法，然后将其丢给 Timer 去执行即可。 Timer 的设计核心是一个 TaskList 和一个 TaskThread。Timer 将接收到的任务丢到自己的 TaskList 中，TaskList 按照 Task 的最初执行时间进行排序。TimerThread 在创建 Timer 时会启动成为一个守护线程。这个线程会轮询所有任务，找到一个最近要执行的任务，然后休眠，当到达最近要执行任务的开始时间点，TimerThread 被唤醒并执行该任务。之后 TimerThread 更新最近一个要执行的任务，继续休眠。 Timer 的优点在于简单易用，但由于 所有任务都是由同一个线程来调度,因此所有任务都是串行执行的，同一时间只能有一个任务在执行，前一个任务的延迟或异常都将会影响到之后的任务。 ScheduledExecutor鉴于 Timer 的上述缺陷，Java 5 推出了基于线程池设计的ScheduledExecutor。其设计思想是，每一个被调度的任务都会由线程池中一个线程去执行，因此任务是并发执行的，相互之间不会受到干扰。需要注意的是，只有当任务的执行时间到来时，ScheduedExecutor才会真正启动一个线程，其余时间 ScheduledExecutor 都是在轮询任务的状态。123456789101112131415161718192021222324252627282930313233343536package com.ibm.scheduler;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;public class ScheduledExecutorTest implements Runnable &#123; private String jobName = ""; public ScheduledExecutorTest(String jobName) &#123; super(); this.jobName = jobName; &#125; @Override public void run() &#123; System.out.println("execute " + jobName); &#125; public static void main(String[] args) &#123; ScheduledExecutorService service = Executors.newScheduledThreadPool(10); long initialDelay1 = 1; long period1 = 1; // 从现在开始1秒钟之后，每隔1秒钟执行一次job1 service.scheduleAtFixedRate( new ScheduledExecutorTest("job1"), initialDelay1, period1, TimeUnit.SECONDS); long initialDelay2 = 1; long delay2 = 1; // 从现在开始2秒钟之后，每隔2秒钟执行一次job2 service.scheduleWithFixedDelay( new ScheduledExecutorTest("job2"), initialDelay2, delay2, TimeUnit.SECONDS); &#125;&#125; 输出：123456execute job1execute job1execute job2execute job1execute job1execute job2 ScheduledExecutorService的两种常用方法： scheduleAtFixedRate:每次执行时间为上一次任务开始起向后推一个时间间隔，即每次执行时间为 :initialDelay, initialDelay+period, initialDelay+2*period, ...； scheduleWithFixedDelay:每次执行时间为上一次任务结束起向后推一个时间间隔，即每次执行时间为：initialDelay, initialDelay+executeTime+delay, initialDelay+2*executeTime+2*delay。 由此可见，ScheduleAtFixedRate是基于固定时间间隔进行任务调度，ScheduleWithFixedDelay取决于每次任务执行的时间长短，是基于不固定时间间隔进行任务调度。 QuartzQuartz可以说是使用相当广泛的任务调度框架了，它够支持更多更负责的调度需求，同时Quartz在设计上将Job和Trigger分离实现了松耦合，这大大增强了任务配置的灵活性 简单的例子用 Quartz 实现每星期二 16:38 的调度安排：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.ibm.scheduler;import java.util.Date;import org.quartz.Job;import org.quartz.JobDetail;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.quartz.Scheduler;import org.quartz.SchedulerFactory;import org.quartz.Trigger;import org.quartz.helpers.TriggerUtils;public class QuartzTest implements Job &#123; @Override //该方法实现需要执行的任务 public void execute(JobExecutionContext arg0) throws JobExecutionException &#123; System.out.println("Generating report - " + arg0.getJobDetail().getFullName() + ", type =" + arg0.getJobDetail().getJobDataMap().get("type")); System.out.println(new Date().toString()); &#125; public static void main(String[] args) &#123; try &#123; // 创建一个Scheduler SchedulerFactory schedFact = new org.quartz.impl.StdSchedulerFactory(); Scheduler sched = schedFact.getScheduler(); sched.start(); // 创建一个JobDetail，指明name，groupname，以及具体的Job类名， //该Job负责定义需要执行任务 JobDetail jobDetail = new JobDetail("myJob", "myJobGroup", QuartzTest.class); jobDetail.getJobDataMap().put("type", "FULL"); // 创建一个每周触发的Trigger，指明星期几几点几分执行 Trigger trigger = TriggerUtils.makeWeeklyTrigger(3, 16, 38); trigger.setGroup("myTriggerGroup"); // 从当前时间的下一秒开始执行 trigger.setStartTime(TriggerUtils.getEvenSecondDate(new Date())); // 指明trigger的name trigger.setName("myTrigger"); // 用scheduler将JobDetail与Trigger关联在一起，开始调度任务 sched.scheduleJob(jobDetail, trigger); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 结果：1234Generating report - myJobGroup.myJob, type =FULLTue Feb 8 16:38:00 CST 2011Generating report - myJobGroup.myJob, type =FULTue Feb 15 16:38:00 CST 2011 非常简洁地实现了一个复杂的任务调度。Quartz 设计的核心类包括 Scheduler, Job 以及Trigger。其中，Job负责定义需要执行的任务，Trigger 负责设置调度策略，Scheduler 将二者组装在一起，并触发任务开始执行。 Job只需要创建一个 Job 的继承类，实现 execute 方法。JobDetail 负责封装 Job 以及 Job 的属性，并将其提供给 Scheduler 作为参数。每次 Scheduler 执行任务时，首先会创建一个 Job 的实例，然后再调用 execute 方法执行。Quartz 没有为 Job 设计带参数的构造函数，因此需要通过额外的 JobDataMap 来存储 Job 的属性。JobDataMap 可以存储任意数量的 Key，Value 对，例如：12345jobDetail.getJobDataMap().put("myDescription", "my job description"); jobDetail.getJobDataMap().put("myValue", 1998); ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add("item1"); jobDetail.getJobDataMap().put("myArray", list); JobDataMap 中的数据可以通过下面的方式获取：12345678910111213141516171819public class JobDataMapTest implements Job &#123; @Override public void execute(JobExecutionContext context) throws JobExecutionException &#123; //从context中获取instName，groupName以及dataMap String instName = context.getJobDetail().getName(); String groupName = context.getJobDetail().getGroup(); JobDataMap dataMap = context.getJobDetail().getJobDataMap(); //从dataMap中获取myDescription，myValue以及myArray String myDescription = dataMap.getString("myDescription"); int myValue = dataMap.getInt("myValue"); ArrayList&lt;String&gt; myArray = (ArrayListlt;Strin&gt;) dataMap.get("myArray"); System.out.println(" Instance =" + instName + ", group = " + groupName + ", description = " + myDescription + ", value =" + myValue + ", array item0 = " + myArray.get(0)); &#125;&#125; TriggerTrigger 的作用是设置调度策略。Quartz 设计了多种类型的 Trigger，其中最常用的是 SimpleTrigger 和 CronTrigger。 SimpleTriggerSimpleTrigger 适用于在某一特定的时间执行一次，或者在某一特定的时间以某一特定时间间隔执行多次。上述功能决定了 SimpleTrigger 的参数包括 start-time, end-time, repeat count, 以及 repeat interval。 Repeat count: 重复次数取值为大于或等于零的整数，或者常量 SimpleTrigger.REPEAT_INDEFINITELY。 Repeat interval: 执行间隔取值为大于或等于零的长整型。当 Repeat interval 取值为0并且 Repeat count取值大于零时，将会触发任务的并发执行。 Start-time 与 end-time 取值为 java.util.Date。当同时指定 end-time 与 repeat count 时，优先考虑 end-time。一般地，可以指定 end-time，并设定 repeat count 为 REPEAT_INDEFINITELY。 以下是 SimpleTrigger 的构造方法：123456public SimpleTrigger(String name, String group, Date startTime, Date endTime, int repeatCount, long repeatInterval) CronTriggerCronTrigger 的用途更广，相比基于特定时间间隔进行调度安排的 SimpleTrigger，CronTrigger 主要适用于基于日历的调度安排。例如：每星期二的 16:38:10 执行，每月一号执行，以及更复杂的调度安排等。CronTrigger 同样需要指定 start-time 和 end-time，其核心在于 Cron 表达式,由七个字段组成（补充中有关于Cron表达式的说明）1234567Seconds Minutes Hours Day-of-Month Month Day-of-Week Year (Optional field) Job 与 Trigger 的松耦合设计是 Quartz 的一大特点，其优点在于同一个 Job 可以绑定多个不同的 Trigger，同一个 Trigger 也可以调度多个 Job，灵活性很强。 Listener除了上述基本的调度功能，Quartz 还提供了 listener 的功能。主要包含三种 listener：JobListener，TriggerListener 以及 SchedulerListener。当系统发生故障，相关人员需要被通知时，Listener 便能发挥它的作用。最常见的情况是，当任务被执行时，系统发生故障，Listener 监听到错误，立即发送邮件给管理员。下面给出 JobListener 的实例：123456789101112131415161718192021222324252627import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.quartz.JobListener;import org.quartz.SchedulerException;public class MyListener implements JobListener&#123; @Override public String getName() &#123; return "My Listener"; &#125; @Override public void jobWasExecuted(JobExecutionContext context, JobExecutionException jobException) &#123; if(jobException != null)&#123; try &#123; //停止Scheduler context.getScheduler().shutdown(); System.out.println("Error occurs when executing jobs, shut down the scheduler "); // 给管理员发送邮件… &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 使用者只需要创建一个 JobListener 的继承类，重载需要触发的方法即可。当然，需要将 listener 的实现类注册到 Scheduler 和 JobDetail 中：12sched.addJobListener(new MyListener()); jobDetail.addJobListener("My Listener"); // listener 的名字 也可以将 listener 注册为全局 listener，这样便可以监听 scheduler 中注册的所有任务 :1sched.addGlobalJobListener(new MyListener()); JobStoresQuartz的另一显著优点在于持久化，即将任务调度的相关数据保存下来。这样，当系统重启后，任务被调度的状态依然存在于系统中，不会丢失。默认情况 下，Quartz采用的是org.quartz.simpl.RAMJobStore，在这种情况下，数据仅能保存在内存中，系统重启后会全部丢失。若想持久化数据，需要采用 org.quartz.simpl.JDBCJobStoreTX。实现持久化的第一步，是要创建 Quartz 持久化所需要的表格。在 Quartz 的发布包 docs/dbTables 中可以找到相应的表格创建脚本。Quartz 支持目前大部分流行的数据库。本文以 DB2 为例，所需要的脚本为 tables_db2.sql。首先需要对脚本做一点小的修改，即在开头指明 Schema：1SET CURRENT SCHEMA quartz; 然后创建数据库 sched，执行 tables_db2.sql 创建持久化所需要的表格。 第二步，配置数据源。数据源与其它所有配置，例如 ThreadPool，均放在 quartz.properties 里：12345678910111213141516# Configure ThreadPool org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool org.quartz.threadPool.threadCount = 5 org.quartz.threadPool.threadPriority = 4 # Configure Datasources org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate org.quartz.jobStore.dataSource = db2DS org.quartz.jobStore.tablePrefix = QRTZ_ org.quartz.dataSource.db2DS.driver = com.ibm.db2.jcc.DB2Driver org.quartz.dataSource.db2DS.URL = jdbc:db2://localhost:50001/sched org.quartz.dataSource.db2DS.user = quartz org.quartz.dataSource.db2DS.password = passw0rd org.quartz.dataSource.db2DS.maxConnections = 5 使用时只需要将 quatz.properties 放在 classpath 下面，再次运行之前的任务调度实例，trigger、job 等信息便会被记录在数据库中。重启服务后将数据库中记录的任务调度数据重新导入程序运行：12345678910111213141516171819202122package com.ibm.scheduler;import org.quartz.Scheduler;import org.quartz.SchedulerException;import org.quartz.SchedulerFactory;import org.quartz.Trigger;import org.quartz.impl.StdSchedulerFactory; public class QuartzReschedulerTest&#123; public static void main(String[]args) throws SchedulerException&#123; //初始化一个 Schedule Factory SchedulerFactory schedulerFactory = new StdSchedulerFactory(); //从 schedule factory 中获取 scheduler Scheduler scheduler = schedulerFactory.getScheduler(); // 从 schedule factory 中获取 trigger Trigger trigger = scheduler.getTrigger("myTrigger","myTriggerGroup"); // 重新开启调度任务 scheduler.rescheduleJob("myTrigger", "myTriggerGroup", trigger); scheduler.start(); &#125;&#125; 上面代码中，schedulerFactory.getScheduler() 将 quartz.properties 的内容加载到内存，然后根据数据源的属性初始化数据库的链接，并将数据库中存储的数据加载到内存。之后，便可以在内存中查询某一具体的 trigger，并将其重新启动。这时候重新查询 qrtz_simple_triggers 中的数据，发现 times_triggered 值比原来增长了。 JCronTabCrontab 是一个非常方便的用于 unix/linux 系统的任务调度命令。JCronTab 则是一款完全按照 crontab 语法编写的 java 任务调度工具。 总结对于简单的基于起始时间点与时间间隔的任务调度，使用 Timer 就足够了；如果需要同时调度多个任务，基于线程池的 ScheduledTimer 是更为合适的选择；当任务调度的策略复杂到难以凭借起始时间点与时间间隔来描述时，Quartz 与 JCronTab 则体现出它们的优势。熟悉 Unix/Linux 的开发人员更倾向于 JCronTab，且 JCronTab 更适合与 Web 应用服务器相结合。Quartz 的 Trigger 与 Job 松耦合设计使其更适用于 Job 与 Trigger 的多对多应用场景。 补充Spring Boot集成QuartzcronExpression表达式介绍 字段 允许值 允许的特殊字符 秒 0-59 , - * / 分 0-59 , - * / 小时 0-23 , - * / 日期 1-31 , - * / L W C 月份 1-12 或者 JAN-DEC , - * / 星期 1-7 或者 SUN-SAT , - * / L C # 年（可选） 留空, 1970-2099 , - * / 如上面的表达式所示: “*”字符被用来指定所有的值。如：”*“在分钟的字段域里表示“每分钟”。 “-”字符被用来指定一个范围。如：“10-12”在小时域意味着“10点、11点、12点”。 “,”字符被用来指定另外的值。如：“MON,WED,FRI”在星期域里表示”星期一、星期三、星期五”. “?”字符只在日期域和星期域中使用。它被用来指定“非明确的值”。当你需要通过在这两个域中的一个来指定一些东西的时候，它是有用的。看下面的例子你就会明白。 “L”字符指定在月或者星期中的某天（最后一天）。即“Last ”的缩写。但是在星期和月中“Ｌ”表示不同的意思，如：在月子段中“L”指月份的最后一天-1月31日，2月28日，如果在星期字段中则简单的表示为“7”或者“SAT”。如果在星期字段中在某个value值得后面，则表示“某月的最后一个星期value”,如“6L”表示某月的最后一个星期五。 “W”字符只能用在月份字段中，该字段指定了离指定日期最近的那个星期日。 “#”字符只能用在星期字段，该字段指定了第几个星期value在某月中 每一个元素都可以显式地规定一个值（如6），一个区间（如9-12），一个列表（如9，11，13）或一个通配符（如*）。“月份中的日期”和“星期中的日期”这两个元素是互斥的，因此应该通过设置一个问号（？）来表明你不想设置的那个字段。表7.1中显示了一些cron表达式的例子和它们的意义： 表达式 意义 “0 0 12 ?” 每天中午12点触发 “0 15 10 ? “ 每天上午10:15触发 “0 15 10 ?” 每天上午10:15触发 “0 15 10 ? *” 每天上午10:15触发 “0 15 10 ? 2005” 2005年的每天上午10:15触发 “0 14 * ?” 在每天下午2点到下午2:59期间的每1分钟触发 “0 0/5 14 ?” 在每天下午2点到下午2:55期间的每5分钟触发 “0 0/5 14,18 ?” 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发 “0 0-5 14 ?” 在每天下午2点到下午2:05期间的每1分钟触发 “0 10,44 14 ? 3 WED” 每年三月的星期三的下午2:10和2:44触发 “0 15 10 ? * MON-FRI” 周一至周五的上午10:15触发 “0 15 10 15 * ?” 每月15日上午10:15触发 “0 15 10 L * ?” 每月最后一日的上午10:15触发 “0 15 10 ? * 6L” 每月的最后一个星期五上午10:15触发 “0 15 10 ? * 6L 2002-2005” 2002年至2005年的每月的最后一个星期五上午10:15触发 “0 15 10 ? * 6#3” 每月的第三个星期五上午10:15触发]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud配置中心————Spring Cloud Config]]></title>
    <url>%2F2018%2F08%2F07%2FSpring-Cloud%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E2%80%94%E2%80%94Spring-Cloud-Config%2F</url>
    <content type="text"><![CDATA[前言似乎从接触计算机编程开始就被告知，不要把程序配置信息硬编码进代码。这自然是有道理的，如果配置信息硬编码进代码，一旦参数发生改变那么是必要对程序进行重新编译，所以才有了后来的配置文件与代码完全分离的方式。我们会把相关配置集中的写在一个配置文件中，这样我们可以在不重新编译代码的情况下实现配置的更改。这种方式适用于少量的应用程序，在微服务大行其道的今天如果还是采用这种方式那么很可能会把运维给逼疯、、、试想一下一个应用程序有100个微服务构成（一点也不夸张）每个服务都有多个实例，如果还是用上面这种方式的话光配置文件就得有几千个…在微服务中主要通过4条原则来约束应用程序的配置管理： 分离——服务配置信息与服务的实际物理部署完全分离开。应用程序的配置不应与服务实例一起部署。相反，配置信息应该作为环境变量传递给正在启动的服务，或者在服务启动时从集中式存储中读取 抽象——将访问配置数据的功能抽象到一个借口服务中。 集中——将应用程序配置集中在尽可能少的存储库中 稳定——高可用]]></content>
      <categories>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+github pages博客之路起航]]></title>
    <url>%2F2018%2F07%2F31%2Fhexo-github-pages%E5%8D%9A%E5%AE%A2%E4%B9%8B%E8%B7%AF%E8%B5%B7%E8%88%AA%2F</url>
    <content type="text"><![CDATA[前言 喜欢写Blog的人，会经历三个阶段。————阮一峰 123- 第一阶段，刚接触Blog，觉得很新鲜，试着选择一个免费空间来写。- 第二阶段，发现免费空间限制太多，就自己购买域名和空间，搭建独立博客。- 第三阶段，觉得独立博客的管理太麻烦，最好在保留控制权的前提下，让别人来管，自己只负责写文章。 由于平时比较懒所以第一、第二阶段虽然都经历过但都没坚持下来（理由吗、、、有很多），平时更多的是通过印象笔记之类的进行知识梳理及记录，但这种三方记录软件存在太多的限制，机缘巧合下遇上了hexo，擦！这不是就是我要找的吗，赶紧拿来学习！说来也惭愧用了这么多年的github直到今天才知道github pages的存在“众里寻他千百度，蓦然回首那人却在灯火阑珊处”说的就是我此时的心情吧。 网上对于如何使用hexo结合github pages搭建私有博客已经有很多教程，本文的目的只是做些简要的记录不做详细说明。对于_config.yml的说明：hexo的位于根目录下站点配置文件，主题配置文件在对应的主题目录下 GitHub Pages Github Pages 是面向用户、组织和项目开放的公共静态页面搭建托管服务，站点可以被免费托管在 Github 上，你可以选择使用 Github Pages 默认提供的域名 github.io 或者自定义域名来发布站点。Github Pages 支持 自动利用 Jekyll 生成站点，也同样支持纯 HTML 文档，将你的 Jekyll 站 点托管在 Github Pages 上是一个不错的选择。 其实对于github pages的创建没什么可说的只需要创建一个“账号名+github.io”的仓库即可。创建完成后即可通过https://cjlovepp.github.io进行访问。 hexo安装配置要使用Hexo，需要在你的系统中支持Nodejs以及Git，如果还没有，ennnnn~~~装呗！ 安装Node.js安装Git安装Hexo关于Hexo的详细使用说明文档参考：https://hexo.io/zh-cn/docs/commands 创建一个空的文件夹（该文件夹用于站点的发布，所以最好不要随便放） Git Bash进入之前创建的目录 12345npm install hexo-cli -g hexo init #初始化网站 npm install hexo g #生成或 hexo generate hexo s #启动本地服务器 或者 hexo server,这一步之后就可以通过http://localhost:4000 查看了 部署到GitHub通过设置”_config.yml”文件中的deploy来配置githup仓库地址，github提交时支持用户名密码和SSH Key两种方式,这里介绍SSH的配置方式 检查SSH keys设置进入git bash123456cd ~/.sshls#如果文件存在直接打开`*.pub`复制内容即可，如果没有则自己生成一个ssh-keygen -t rsa -C "邮件地址@youremail.com" #生成新的key文件,邮箱地址填你的Github地址#Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa):&lt;回车就好&gt;#接下来会让你输入密码（直接回车也可以） 添加SSH Key到Github进入github首页找到对应的repository，进入setting将key添加到deploy keys中。123#测试是否成功ssh -T git@github.com#之后会要你输入yes/no,输入yes就好了。 部署到github1hexo d 没错，就是这么简单。结束！ 补充图片存储解决写技术类文章没有图片怎么行？一张到位的图片能省去大篇幅的文字说明（还不一定说的清），所以博客中插入图片便成了刚需，那么问题来了图片存哪合适呢？网上通用的解决方案 七牛云 我也曾用过一段时间，说实在的问题是解决了但体验并不是很好（每次要把图片先上传到七牛的服务器然后再使用），所以果断放弃！在hexo发展至今都没有一个好的图片解决方案？开什么玩笑—-hexo-asset-image，对喽就是这货，来看看具体怎么用吧。 首先确认_config.yml 中开启 post_asset_folder:true。Hexo 提供了一种更方便管理 Asset 的设定：post_asset_folder当您设置post_asset_folder为true参数后，在建立文件时，Hexo会自动建立一个与文章同名的文件夹，您可以把与该文章相关的所有资源都放到那个文件夹，如此一来，您便可以更方便的使用资源。 安装 hexo-asset-image 1npm install hexo-asset-image --save 完成安装后用hexo新建文章的时候会发现_posts目录下面会多出一个和文章名字一样的文件夹。图片就可以放在文件夹下面。结构如下： 12345本地图片测试├── apppicker.jpg├── logo.jpg└── rules.jpg本地图片测试.md 这样的目录结构（目录名和文章名一致），只要使用 ![logo](本地图片测试/logo.jpg) 就可以插入图片。生成的结构为12345public/2016/3/9/本地图片测试├── apppicker.jpg├── index.html├── logo.jpg└── rules.jpg 同时，生成的 html 是 1&lt;img src="/2016/3/9/本地图片测试/logo.jpg" alt="logo"&gt; 而不是1&lt;img src="本地图片测试/logo.jpg" alt="logo"&gt; 这种方式存在一个明显的弊端就是随着使用git会越来越大，但就目前我的需求来讲暂时不用考虑这些问题 hexo主题配置hexo只是很多主题获取主题的方式当然是通过官网 主题，如何启用主题都有对应的说明此处不多废话，进过精挑细后还是觉定采用社区比较认可的NexT,详细的使用说明可以参考 中文文档 hexo插件可以去 插件 找到很多有用的插件 添加【分类，标签】等功能hexo可以对博客进行标签分类，侧边栏添加并实现分类和标签功能的做法类似，这里以分类为例 创建分类显示页面1hexo new page categories 你会发现你的source文件夹下有了categorcies/index.md，之所以命名为categories的原因是在next主题的配置文件中，categories是关键词。 编辑新建界面，将页面类型设置为categories，主题将会在这个页面上显示所有的分类：12345---title: categoriesdate: 2018-03-02 12:33:16type: "categories" //这点尤为重要否则分类页是空的--- 另外就是，需要注意一点：如果有启用多说 或者 Disqus 评论，默认页面也会带有评论。需要关闭的话，请添加字段 comments 并将值设置为 false，如：123456---title: categoriesdate: 2018-03-02 12:33:16type: "categories"comments: false--- 在菜单中添加链接，此时需要编辑主题的_config.yml，hexo的配置文件事先写好了，但是处于注释状态，需要去除注释即可： 123456menu: home: / || home about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive 添加文章分类关联把文章归入分类只需在文章的顶部标题下方添加categories字段，即可自动创建分类名并加入对应的分类中： 12345678---title: hexo+github pages博客之路起航date: 2018-07-31 17:08:10tags: - hexo - github pagescategories: hexo--- 添加搜索 1、安装 hexo-generator-searchdb 插件 1$ npm install hexo-generator-searchdb --save 2、打开 站点配置文件` 找到Extensions在下面添加 123456# 搜索search: path: search.xml field: post format: html limit: 10000 3、打开 主题配置文件` 找到Local search，将enable设置为true 添加阅读全文按钮因为在你的博客主页会有多篇文章，如果你想让你的文章只显示一部分，多余的可以点击阅读全文来查看，那么你需要在你的文章中添加1&lt;!--more--&gt; 其后面的部分就不会显示了，只能点击阅读全文才能看 提交hexo源码到githubhexo在将网站发布到github时只是将生成的静态页同步到github中，而编写的文件源码（xxx.md）并不会上传到git。这样的话当我们数据损坏或者需要在别的地方编写时就会很尴尬。所以最好的方式是我们把hexo源代码也上传到github中。 建立分支：因为 master 分支是存放 Hexo 博客生成的页面，所以只能创建一个分支来保存博客的源代码在你的 GitHub 设置默认分支为 hexo这里需要有注意站点配置文件 _config.yml 的 deploy 需要设置成 master OK，提交到代码到 hexo 分支即可 添加背景图片给hexo next添加背景图片，只需要在 themes\next\source\css\_custom\custom.styl 添加如下代码即可：12345678910111213@media screen and (min-width:1200px) &#123; body &#123; background-image:url(/images/background.jpg); background-repeat: no-repeat; background-attachment:fixed; background-position:50% 50%; &#125; #footer a &#123; color:#eee; &#125;&#125; 字数统计用于统计文章的字数以及分析出阅读时间。 添加hexo-wordcount插件 1npm install hexo-wordcount --save 在主题配置文件中，搜索wordcount，设置为下面这样就可以了： 123456post_wordcount: item_text: true wordcount: true min2read: true totalcount: true separated_meta: true 再打开\themes\next\layout\_macro\post.swig 文件，在leancloud-visitors-count后面位置添加一个分割符： 1234 &lt;span class=&quot;leancloud-visitors-count&quot;&gt;&lt;/span&gt; &lt;/span&gt; &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt;&#123;% endif %&#125; 自动部署到github pages]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
